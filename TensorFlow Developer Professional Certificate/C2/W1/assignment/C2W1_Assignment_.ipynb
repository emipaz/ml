{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/IngCarlaPezzone/tensorflow-1-public/blob/main/C2/W1/assignment/C2W1_Assignment_traducida.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuW-xg_bTsaF"
   },
   "source": [
    "# Semana 1: Uso de CNN con el conjunto de datos Cats vs Dogs\n",
    "\n",
    "Bienvenido a la primera tarea del curso. Esta semana, utilizarás el famoso conjunto de datos `Gatos vs Perros` para entrenar un modelo que pueda clasificar imágenes de perros de imágenes de gatos. Para ello, crearás tu propia red neuronal convolucional en Tensorflow y aprovecharás las utilidades de preprocesamiento de imágenes de Keras.\n",
    "\n",
    "También crearás algunas funciones de ayuda para mover las imágenes por el sistema de archivos, así que si no estás familiarizado con el módulo `os` asegúrate de echar un vistazo a los [docs](https://docs.python.org/3/library/os.html).\n",
    "\n",
    "¡Empecemos!\n",
    "\n",
    "<details><summary>Texto Original</summary>\n",
    "\n",
    "# Week 1: Using CNN's with the Cats vs Dogs Dataset\n",
    "\n",
    "Welcome to the 1st assignment of the course! This week, you will be using the famous `Cats vs Dogs` dataset to train a model that can classify images of dogs from images of cats. For this, you will create your own Convolutional Neural Network in Tensorflow and leverage Keras' image preprocessing utilities.\n",
    "\n",
    "You will also create some helper functions to move the images around the filesystem so if you are not familiar with the `os` module be sure to take a look a the [docs](https://docs.python.org/3/library/os.html).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instale este paquete para utilizar la GPU de Colab para la formación\n",
    "!apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dn-6c02VmqiN",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLTQd84RUs1j"
   },
   "source": [
    "Descargue el conjunto de datos desde su fuente original ejecutando la celda que aparece a continuación. \n",
    "\n",
    "Tenga en cuenta que el archivo `zip` que contiene las imágenes se descomprime en el directorio `/tmp`.\n",
    "\n",
    "<details><summary>Texto Original</summary>\n",
    "\n",
    "Download the dataset from its original source by running the cell below. \n",
    "\n",
    "Note that the `zip` file that contains the images is unzipped under the `/tmp` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sd9dQWa23aj",
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Si la URL no funciona, visite https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
    "# Y haz clic con el botón derecho del ratón en el enlace \"Descargar manualmente\" para obtener \n",
    "# una nueva URL del conjunto de datos\n",
    "\n",
    "# Nota: Este conjunto de datos es muy grande y tardará en descargarse\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\" \\\n",
    "    -O \"/tmp/cats-and-dogs.zip\"\n",
    "\n",
    "local_zip = '/tmp/cats-and-dogs.zip'\n",
    "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_HsUV9WVJHL"
   },
   "source": [
    "Ahora las imágenes se almacenan en el directorio `/tmp/PetImages`. Hay un subdirectorio para cada clase, así que uno para perros y otro para gatos.\n",
    "\n",
    "<details><summary>Texto Original</summary>\n",
    "\n",
    "Now the images are stored within the `/tmp/PetImages` directory. There is a subdirectory for each class, so one for dogs and one for cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DM851ZmN28J3",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "source_path = '/tmp/PetImages'\n",
    "\n",
    "source_path_dogs = os.path.join(source_path, 'Dog')\n",
    "source_path_cats = os.path.join(source_path, 'Cat')\n",
    "\n",
    "# Elimina todos los archivos que no son de imagen (hay dos archivos .db incluidos en el conjunto de datos)\n",
    "!find /tmp/PetImages/ -type f ! -name \"*.jpg\" -exec rm {} +\n",
    "\n",
    "# os.listdir devuelve una lista que contiene todos los archivos bajo la ruta dada\n",
    "print(f\"There are {len(os.listdir(source_path_dogs))} images of dogs.\")\n",
    "print(f\"There are {len(os.listdir(source_path_cats))} images of cats.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7dI86rmRGmC"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "There are 12501 images of dogs.\n",
    "There are 12501 images of cats.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFbMliudNIjW"
   },
   "source": [
    "Necesitará un directorio para cats-v-dogs, y subdirectorios para el entrenamiento\n",
    "y la validación. Estos, a su vez, necesitarán subdirectorios para `gatos' y `perros'. Para lograr esto, complete el `create_train_val_dirs` a continuación:\n",
    "\n",
    "<details><summary>Texto Original</summary>\n",
    "\n",
    "You will need a directory for cats-v-dogs, and subdirectories for training\n",
    "and validation. These in turn will need subdirectories for 'cats' and 'dogs'. To accomplish this, complete the `create_train_val_dirs` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "F-QkLjxpmyK2",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Definir el directorio raíz\n",
    "root_dir = '/tmp/cats-v-dogs'\n",
    "\n",
    "# Directorio vacío para evitar FileExistsError si la función se ejecuta varias veces\n",
    "if os.path.exists(root_dir):\n",
    "  shutil.rmtree(root_dir)\n",
    "\n",
    "# GRADED FUNCTION: crear_dirigir_valores_de_entrenamiento\n",
    "def create_train_val_dirs(root_path):\n",
    "  \"\"\"\n",
    "  Creates directories for the train and test sets\n",
    "  \n",
    "  Args:\n",
    "    root_path (string) - the base directory path to create subdirectories from\n",
    "  \n",
    "  Returns:\n",
    "    None\n",
    "  \"\"\"  \n",
    "  ### START CODE HERE\n",
    "\n",
    "  # HINT:\n",
    "  # Utilice os.makedirs para crear sus directorios con subdirectorios intermedios\n",
    "  # No codifique las rutas. Utilice os.path.join para añadir los nuevos directorios al parámetro root_path\n",
    "\n",
    "  pass\n",
    "\n",
    "  ### END CODE HERE\n",
    "\n",
    "  \n",
    "try:\n",
    "  create_train_val_dirs(root_path=root_dir)\n",
    "except FileExistsError:\n",
    "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dhtL344OK00",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Test your create_train_val_dirs function\n",
    "\n",
    "for rootdir, dirs, files in os.walk(root_dir):\n",
    "    for subdir in dirs:\n",
    "        print(os.path.join(rootdir, subdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7A0RK3IQsvg"
   },
   "source": [
    "**Expected Output (directory order might vary):**\n",
    "\n",
    "``` txt\n",
    "/tmp/cats-v-dogs/training\n",
    "/tmp/cats-v-dogs/validation\n",
    "/tmp/cats-v-dogs/training/cats\n",
    "/tmp/cats-v-dogs/training/dogs\n",
    "/tmp/cats-v-dogs/validation/cats\n",
    "/tmp/cats-v-dogs/validation/dogs\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R93T7HdE5txZ"
   },
   "source": [
    "Codifique la función `split_data` que recibe los siguientes argumentos:\n",
    "- SOURCE_DIR: directorio que contiene los archivos\n",
    "\n",
    "- TRAINING_DIR: directorio en el que se copiará una parte de los archivos (se utilizará para el entrenamiento)\n",
    "- VALIDATION_DIR: directorio en el que se copiará una parte de los archivos (se utilizará para la validación)\n",
    "- SPLIT_SIZE: determina la porción de imágenes utilizadas para el entrenamiento.\n",
    "\n",
    "Los archivos deben ser aleatorios, de modo que el conjunto de entrenamiento sea una muestra aleatoria de los archivos, y el conjunto de validación esté formado por los archivos restantes.\n",
    "\n",
    "Por ejemplo, si `SOURCE_DIR` es `PetImages/Cat`, y `SPLIT_SIZE` es .9 entonces el 90% de las imágenes de `PetImages/Cat` se copiarán en el directorio `TRAINING_DIR\n",
    "y el 10% de las imágenes se copiarán en el directorio `VALIDATION_DIR`.\n",
    "\n",
    "Todas las imágenes deben ser comprobadas antes de la copia, por lo que si tienen una longitud de archivo cero, serán omitidas del proceso de copia. Si este es el caso, su función debería imprimir un mensaje como `\"el nombre del archivo tiene longitud cero, por lo que se ignora\". **Debería realizar esta comprobación antes de la división para que sólo se tengan en cuenta las imágenes que no sean cero cuando se realice la división real.\n",
    "\n",
    "\n",
    "Sugerencias:\n",
    "\n",
    "- `os.listdir(DIRECTORY)` devuelve una lista con el contenido de ese directorio.\n",
    "\n",
    "- `os.path.getsize(PATH)` devuelve el tamaño del archivo\n",
    "\n",
    "- `copyfile(origen, destino)` copia un fichero del origen al destino\n",
    "\n",
    "- `random.sample(list, len(list))` baraja una lista\n",
    "\n",
    "<details><summary>Texto Original</summary>\n",
    "\n",
    "Code the `split_data` function which takes in the following arguments:\n",
    "- SOURCE_DIR: directory containing the files\n",
    "\n",
    "- TRAINING_DIR: directory that a portion of the files will be copied to (will be used for training)\n",
    "- VALIDATION_DIR: directory that a portion of the files will be copied to (will be used for validation)\n",
    "- SPLIT_SIZE: determines the portion of images used for training.\n",
    "\n",
    "The files should be randomized, so that the training set is a random sample of the files, and the validation set is made up of the remaining files.\n",
    "\n",
    "For example, if `SOURCE_DIR` is `PetImages/Cat`, and `SPLIT_SIZE` is .9 then 90% of the images in `PetImages/Cat` will be copied to the `TRAINING_DIR` directory\n",
    "and 10% of the images will be copied to the `VALIDATION_DIR` directory.\n",
    "\n",
    "All images should be checked before the copy, so if they have a zero file length, they will be omitted from the copying process. If this is the case then your function should print out a message such as `\"filename is zero length, so ignoring.\"`. **You should perform this check before the split so that only non-zero images are considered when doing the actual split.**\n",
    "\n",
    "\n",
    "Hints:\n",
    "\n",
    "- `os.listdir(DIRECTORY)` returns a list with the contents of that directory.\n",
    "\n",
    "- `os.path.getsize(PATH)` returns the size of the file\n",
    "\n",
    "- `copyfile(source, destination)` copies a file from source to destination\n",
    "\n",
    "- `random.sample(list, len(list))` shuffles a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "zvSODo0f9LaU",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: split_data\n",
    "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
    "  \"\"\"\n",
    "  Splits the data into train and test sets\n",
    "  \n",
    "  Args:\n",
    "    SOURCE_DIR (string): directory path containing the images\n",
    "    TRAINING_DIR (string): directory path to be used for training\n",
    "    VALIDATION_DIR (string): directory path to be used for validation\n",
    "    SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
    "    \n",
    "  Returns:\n",
    "    None\n",
    "  \"\"\"\n",
    "\n",
    "  ### START CODE HERE\n",
    "    pass\n",
    "\n",
    "  ### END CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FlIdoUeX9S-9",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Test your split_data function\n",
    "\n",
    "# Define paths\n",
    "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
    "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
    "\n",
    "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
    "VALIDATION_DIR = \"/tmp/cats-v-dogs/validation/\"\n",
    "\n",
    "TRAINING_CATS_DIR = os.path.join(TRAINING_DIR, \"cats/\")\n",
    "VALIDATION_CATS_DIR = os.path.join(VALIDATION_DIR, \"cats/\")\n",
    "\n",
    "TRAINING_DOGS_DIR = os.path.join(TRAINING_DIR, \"dogs/\")\n",
    "VALIDATION_DOGS_DIR = os.path.join(VALIDATION_DIR, \"dogs/\")\n",
    "\n",
    "# Empty directories in case you run this cell multiple times\n",
    "if len(os.listdir(TRAINING_CATS_DIR)) > 0:\n",
    "    for file in os.scandir(TRAINING_CATS_DIR):\n",
    "        os.remove(file.path)\n",
    "if len(os.listdir(TRAINING_DOGS_DIR)) > 0:\n",
    "    for file in os.scandir(TRAINING_DOGS_DIR):\n",
    "        os.remove(file.path)\n",
    "if len(os.listdir(VALIDATION_CATS_DIR)) > 0:\n",
    "    for file in os.scandir(VALIDATION_CATS_DIR):\n",
    "        os.remove(file.path)\n",
    "if len(os.listdir(VALIDATION_DOGS_DIR)) > 0:\n",
    "    for file in os.scandir(VALIDATION_DOGS_DIR):\n",
    "        os.remove(file.path)\n",
    "\n",
    "# Definir la proporción de imágenes utilizadas para el entrenamiento\n",
    "split_size = .9\n",
    "\n",
    "# Ejecute la función\n",
    "# NOTA: Los mensajes sobre las imágenes de longitud cero deben imprimirse\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, VALIDATION_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, VALIDATION_DOGS_DIR, split_size)\n",
    "\n",
    "# Comprueba que el número de imágenes coincide con la salida esperada\n",
    "\n",
    "# Su función debe realizar copias en lugar de mover las imágenes, por lo que los \n",
    "# directorios originales deben contener imágenes sin cambios\n",
    "print(f\"\\n\\nOriginal cat's directory has {len(os.listdir(CAT_SOURCE_DIR))} images\")\n",
    "print(f\"Original dog's directory has {len(os.listdir(DOG_SOURCE_DIR))} images\\n\")\n",
    "\n",
    "# Training and validation splits\n",
    "print(f\"There are {len(os.listdir(TRAINING_CATS_DIR))} images of cats for training\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_DOGS_DIR))} images of dogs for training\")\n",
    "print(f\"There are {len(os.listdir(VALIDATION_CATS_DIR))} images of cats for validation\")\n",
    "print(f\"There are {len(os.listdir(VALIDATION_DOGS_DIR))} images of dogs for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvskJNOFVSaz"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "666.jpg is zero length, so ignoring.\n",
    "11702.jpg is zero length, so ignoring.\n",
    "\n",
    "\n",
    "Original cat's directory has 12500 images\n",
    "Original dog's directory has 12500 images\n",
    "\n",
    "There are 11249 images of cats for training\n",
    "There are 11249 images of dogs for training\n",
    "There are 1250 images of cats for validation\n",
    "There are 1250 images of dogs for validation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zil4QmOD_mXF"
   },
   "source": [
    "Ahora que has organizado con éxito los datos de una manera que puede ser fácilmente alimentada por el `ImageDataGenerator` de Keras, es el momento de codificar los generadores que producirán lotes de imágenes, tanto para el entrenamiento como para la validación. Para ello, completa la función `train_val_generators` de abajo.\n",
    "\n",
    "Algo importante a tener en cuenta es que las imágenes de este conjunto de datos vienen en una variedad de resoluciones. Por suerte, el método `flow_from_directory` te permite estandarizar esto definiendo una tupla llamada `target_size` que se utilizará para convertir cada imagen a esta resolución objetivo. **Para este ejercicio, utiliza un \"target_size\" de (150, 150)**.\n",
    "\n",
    "**Consejo:** \n",
    "\n",
    "No utilices el aumento de datos estableciendo parámetros extra cuando instales la clase `ImageDataGenerator`. Esto hará que el entrenamiento de tu modelo tarde más tiempo en alcanzar el umbral de precisión necesario para aprobar esta tarea y este tema se tratará en la próxima semana.\n",
    "\n",
    "<details><summary>Texto Original</summary>\n",
    "\n",
    "Now that you have successfully organized the data in a way that can be easily fed to Keras' `ImageDataGenerator`, it is time for you to code the generators that will yield batches of images, both for training and validation. For this, complete the `train_val_generators` function below.\n",
    "\n",
    "Something important to note is that the images in this dataset come in a variety of resolutions. Luckily, the `flow_from_directory` method allows you to standarize this by defining a tuple called `target_size` that will be used to convert each image to this target resolution. **For this exercise, use a `target_size` of (150, 150)**.\n",
    "\n",
    "**Hint:** \n",
    "\n",
    "Don't use data augmentation by setting extra parameters when you instantiate the `ImageDataGenerator` class. This will make the training of your model to take longer to reach the necessary accuracy threshold to pass this assignment and this topic will be covered in the next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "fQrZfVgz4j2g",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_val_generators\n",
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "  \"\"\"\n",
    "  Creates the training and validation data generators\n",
    "  \n",
    "  Args:\n",
    "    TRAINING_DIR (string): directory path containing the training images\n",
    "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
    "    \n",
    "  Returns:\n",
    "    train_generator, validation_generator - tuple containing the generators\n",
    "  \"\"\"\n",
    "  ### START CODE HERE\n",
    "\n",
    "  # Instancie la clase ImageDataGenerator (no olvide establecer el argumento rescale)\n",
    "  train_datagen = None\n",
    "\n",
    "  # Pasar los argumentos adecuados al método flow_from_directory\n",
    "  train_generator = train_datagen.flow_from_directory(directory=None,\n",
    "                                                      batch_size=None,\n",
    "                                                      class_mode=None,\n",
    "                                                      target_size=(None, None))\n",
    "\n",
    "  # Instancie la clase ImageDataGenerator (no olvide establecer el argumento rescale)\n",
    "  validation_datagen = None\n",
    "\n",
    "  # Pasar los argumentos adecuados al método flow_from_directory\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=None,\n",
    "                                                                batch_size=None,\n",
    "                                                                class_mode=None,\n",
    "                                                                target_size=(None, None))\n",
    "  ### END CODE HERE\n",
    "  return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qM7FxrjGiobD",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Test your generators\n",
    "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiPNmSfZjHwJ"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "Found 22498 images belonging to 2 classes.\n",
    "Found 2500 images belonging to 2 classes.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI3oEmyQCZoO"
   },
   "source": [
    "Un último paso antes del entrenamiento es definir la arquitectura del modelo que será entrenado.\n",
    "\n",
    "Completa la función `create_model` que aparece a continuación y que debería devolver un modelo `Secuencial` de Keras.\n",
    "\n",
    "Además de definir la arquitectura del modelo, también debes compilarlo, así que asegúrate de usar una función `loss` que sea compatible con el `class_mode` que definiste en el ejercicio anterior, que también debería ser compatible con la salida de tu red. Puedes saber si no son compatibles si obtienes un error durante el entrenamiento.\n",
    "\n",
    "**Ten en cuenta que debes utilizar al menos 3 capas de convolución para conseguir el rendimiento deseado.**\n",
    "\n",
    "\n",
    "<details><summary>Texto Original</summary>\n",
    "\n",
    "One last step before training is to define the architecture of the model that will be trained.\n",
    "\n",
    "Complete the `create_model` function below which should return a Keras' `Sequential` model.\n",
    "\n",
    "Aside from defining the architecture of the model, you should also compile it so make sure to use a `loss` function that is compatible with the `class_mode` you defined in the previous exercise, which should also be compatible with the output of your network. You can tell if they aren't compatible if you get an error during training.\n",
    "\n",
    "**Note that you should use at least 3 convolution layers to achieve the desired performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "oDPK8tUB_O9e",
    "lines_to_next_cell": 2,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_model\n",
    "def create_model():\n",
    "  # DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
    "  # USE AT LEAST 3 CONVOLUTION LAYERS\n",
    "\n",
    "  ### START CODE HERE\n",
    "\n",
    "  model = tf.keras.models.Sequential([ \n",
    "      None,\n",
    "  ])\n",
    "\n",
    "  \n",
    "  model.compile(optimizer=None,\n",
    "                loss=None,\n",
    "                metrics=['accuracy']) \n",
    "    \n",
    "  ### END CODE HERE\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMFNJZmTCZv6"
   },
   "source": [
    "¡Ahora es el momento de entrenar su modelo!\n",
    "\n",
    "**Nota:** Puede ignorar las advertencias `UserWarning: Posiblemente datos EXIF corruptos.`.\n",
    "\n",
    "<details><summary>Texto Original</summary>\n",
    "\n",
    "Now it is time to train your model!\n",
    "\n",
    "**Note:** You can ignore the `UserWarning: Possibly corrupt EXIF data.` warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qE1G6JB4fMn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtener el modelo no entrenado\n",
    "model = create_model()\n",
    "\n",
    "# Entrenar el modelo\n",
    "# Tenga en cuenta que esto puede llevar algún tiempo.\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=15,\n",
    "                    verbose=1,\n",
    "                    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGsaDMc-GMd4"
   },
   "source": [
    "Una vez finalizado el entrenamiento, puede ejecutar la siguiente celda para comprobar la precisión de entrenamiento y validación alcanzada al final de cada época.\n",
    "\n",
    "**Para aprobar esta tarea, tu modelo debe alcanzar una precisión de entrenamiento de al menos el 95% y una precisión de validación de al menos el 80%**. Si tu modelo no alcanza estos umbrales, intenta entrenar de nuevo con una arquitectura de modelo diferente y recuerda utilizar al menos 3 capas convolucionales.\n",
    "\n",
    "<details><summary>Texto Original</summary>\n",
    "\n",
    "Once training has finished, you can run the following cell to check the training and validation accuracy achieved at the end of each epoch.\n",
    "\n",
    "**To pass this assignment, your model should achieve a training accuracy of at least 95% and a validation accuracy of at least 80%**. If your model didn't achieve these thresholds, try training again with a different model architecture and remember to use at least 3 convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWZrJN4-65RC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Recuperar una lista de resultados de la lista en los datos de entrenamiento y de prueba\n",
    "# conjuntos para cada época de entrenamiento\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Trazar la precisión de entrenamiento y validación por época\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.show()\n",
    "print(\"\")\n",
    "\n",
    "#------------------------------------------------\n",
    "# Trazar la pérdida de entrenamiento y validación por época\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYIaqsN2pav6"
   },
   "source": [
    "Es probable que encuentre que el modelo está sobreajustado, lo que significa que está haciendo un gran trabajo en la clasificación de las imágenes en el conjunto de entrenamiento, pero tiene dificultades con los nuevos datos. Esto está perfectamente bien y usted aprenderá a mitigar este problema en la próxima semana.\n",
    "\n",
    "Antes de descargar este cuaderno y cerrar la tarea, asegúrese de descargar también el archivo `history.pkl` que contiene la información del historial de entrenamiento de su modelo. Puede descargar este archivo ejecutando la celda de abajo:\n",
    "\n",
    "<details><summary>Texto Original</summary>\n",
    "\n",
    "You will probably encounter that the model is overfitting, which means that it is doing a great job at classifying the images in the training set but struggles with new data. This is perfectly fine and you will learn how to mitigate this issue in the upcoming week.\n",
    "\n",
    "Before downloading this notebook and closing the assignment, be sure to also download the `history.pkl` file which contains the information of the training history of your model. You can download this file by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWcrc9nZTsHj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_history():\n",
    "    import pickle\n",
    "    from google.colab import files\n",
    "\n",
    "    with open('history.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    files.download('history.pkl')\n",
    "\n",
    "download_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También tendrá que presentar este cuaderno para su calificación. Para descargarlo, haga clic en la pestaña `File` en la esquina superior izquierda de la pantalla y luego haga clic en `Download` -> `Download .ipynb`. Puedes ponerle el nombre que quieras siempre que sea un archivo válido `.ipynb` (cuaderno jupyter).\n",
    "\n",
    "<details><summary>Texto Original</summary>\n",
    "\n",
    "You will also need to submit this notebook for grading. To download it, click on the `File` tab in the upper left corner of the screen then click on `Download` -> `Download .ipynb`. You can name it anything you want as long as it is a valid `.ipynb` (jupyter notebook) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joAaZSWWpbOI"
   },
   "source": [
    "**Felicitaciones por haber terminado la tarea de esta semana.\n",
    "\n",
    "Has implementado con éxito una red neuronal convolucional que clasifica imágenes de gatos y perros, junto con las funciones de ayuda necesarias para preprocesar las imágenes.\n",
    "\n",
    "**Sigue así.**\n",
    "\n",
    "<details><summary>Texto Original</summary>\n",
    "\n",
    "**Congratulations on finishing this week's assignment!**\n",
    "\n",
    "You have successfully implemented a convolutional neural network that classifies images of cats and dogs, along with the helper functions needed to pre-process the images!\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
