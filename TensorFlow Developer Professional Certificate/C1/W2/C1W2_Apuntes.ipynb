{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TENSORFLOW DEVELOPER PROFESSIONAL CERTIFICATE**\n",
    "# Curso 1: Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning\n",
    "# Semana 2: Introduction to Computer Vision\n",
    "\n",
    "*Esta notebook plasma los apuntes traducidos al español del Curso dicatado por [DeepLearning.AI](https://www.deeplearning.ai/courses/), por lo que puede encontrar errores. Las figuras y ecuaciones se han obtenido/adaptado directamente de las diapositivas utilizadas en el curso. Todo el mérito es de los instructores. Simplemente espero que los apuntes sirvan como material de estudio complementario.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION TO COMPUTER VISION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Conversation with Andrew Ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esa lección, vimos los fundamentos del nuevo paradigma de programación que viene con el aprendizaje automático y el aprendizaje profundo, y cómo en vez de expresar reglas en un lenguaje de programación, podemos empezar a obtener datos y usar datos etiquetados para abrir nuevos escenarios como el reconocimiento de actividad. Luego por un poco de diversión, empezamos a hacer el primer trozo de código. Construimos una red neuronal super sencilla que ajusta datos como x e y en una línea pero eso solo fue \"Hola Mundo\". ¿Correcto, Andrew? \n",
    "\n",
    "Ajustar líneas rectas parece la implementación de algoritmo de aprendizaje más básico del \"Hola, Mundo\". Pero una de las cosas más sorprendentes del aprendizaje automático es que, el núcleo de la idea de ajustar la relación x e y es lo que nos permite hacer cosas asombrosas como hacer que las computadoras vean una imagen y hagan reconocimiento de actividad, o vean la imagen y nos digan, que es un vestido, o un par de pantalones, o un par de zapatos muy difícil para los humanos, y asombroso que las computadoras puedan usar esto para hacer esas cosas también. ¿Como la visión por computadora es un problema realmente difícil de resolver?. Porque estás diciendo vestido o zapatos. ¿Cómo podrías escribir reglas para eso? Cómo dirías, si este píxel entonces es un zapato, si ese píxel entonces es un vestido. Es realmente difícil hacerlo, las muestras etiquetadas son la forma correcta de hacerlo. \n",
    "\n",
    "Así es. Una de las cosas no intuitivas en visión es que es muy fácil para una persona verte y decir tú llevas una camiseta, es muy difícil para una computadora averiguarlo. Como es muy fácil para los humanos reconocer objetos, es difícil de entender por qué esto es una cosa complicada de hacer para una computadora. Lo que la computadora tiene que hacer es ver todos los números, todos los valores de brillo de los píxeles, mirando todos estos números diciendo, estos números corresponden a una camiseta negra, y es asombroso que con los aprendizajes automático y profundo las computadoras llegan a ser realmente muy buenas en esto. Es como con el código que acabamos de usar en la lección previa como mencionaste, proporciona una plantilla para todo lo que podemos hacer con el aprendizaje profundo diseñando una red neuronal en las capas para ser capaz de reconocer patrones así. Posiblemente podemos hacerlo con reconocimiento de ropa hoy. ¿Qué piensas? Sí. \n",
    "\n",
    "En el siguiente vídeo, aprenderás cómo escribir código para tomar este paradigma que ya viste en un vídeo anterior, y aplicarlo ahora para reconocer ropa a partir de datos etiquetados. Por favor continúen con el siguiente vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Introduction to computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la lección anterior, vimos aprendiste qué es el paradigma de aprendizaje automático y cómo usar datos y etiquetas y hacer que una computadora infiera las reglas por ti. Viste un ejemplo sencillo donde averiguaba las relaciones entre dos conjuntos de números. Llevemos esto al siguiente nivel resolviendo un problema real, visión por computadora. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W2_Página_02.jpg\", style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n",
    "**Visión por computadora** es el campo en el que una computadora entiende y etiqueta lo que está presente en una imagen. Considera esta diapositiva. Cuando la ves, puedes interpretar que es una camisa o que es un zapato, ¿pero cómo lo programarías? Si un extraterrestre que nunca ha visto ropa entra en el cuarto contigo, ¿Como le explicarías los zapatos? Es realmente muy difícil, sino imposible hacerlo. Y es el mismo problema con la visión por computadora. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W2_Página_03.jpg\", style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n",
    "Una forma de resolverlo es utilizar un montón de imágenes de ropa decirle al computador qué es esa imagen y luego dejar que la computadora averigüe los patrones que te dan la diferencia entre un zapato una camiseta, una cartera, y un abrigo. Aprenderás cómo hacerlo en esta sección. Afortunadamente, existe un conjunto de datos llamado Fashion MNIST que da 70 mil imágenes distribuidas en 10 diferentes artículos de ropa. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W2_Página_04.jpg\", style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n",
    "Estas imágenes han sido reducidas a 28 por 28 píxeles. Usualmente, cuanto más pequeño, mejor porque la computadora debe hacer menos procesamiento. Pero por supuesto, debes retener suficiente información para estar seguro de que las características y el objeto se puedan distinguir. Si ves esta diapositiva puedes decir la diferencia entre camisetas, zapatos y carteras. Este tamaño parece ser ideal, y lo hace genial para entrenar una red neuronal. Las imágenes están también en escala gris, la cantidad de información también ha sido reducida. Cada píxel puede ser representado en valores desde cero hasta 255 y sólo es un byte por píxel. Con 28 por 28 píxeles por imagen, solo 784 bytes son necesarios para almacenar la imagen completa. A pesar de eso, podemos aún ver qué hay en la imagen y en este caso, es un botín."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring how to use data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje automático depende de tener buenos datos con los que entrenar un sistema. En el vídeo anterior, se le dio un escenario para entrenar un sistema para reconocer imágenes de moda. Los datos provienen de un conjunto de datos llamado Fashion MNIST, y puedes aprender más sobre él en GitHub [aquí](https://github.com/zalandoresearch/fashion-mnist). En el siguiente vídeo, verás cómo cargar esos datos y prepararlos para el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing code to load training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué aspecto tendrá el manejo de esto en código? En la lección anterior, vimos aprendiste de TensorFlow y Keras, y cómo definir una red neuronal sencilla con ellos. En esta lección, las usarás para ir un poco más a fondo, pero el API en general debe parecerte familiar. La única gran diferencia, estará en los datos. La última vez tenías 6 pares de números, y podías codificarlo a mano. Esta vez, debes cargar 70000 imágenes del disco, habrá un poco de código para manejar eso. Afortunadamente, aún es bastante sencillo porque Fashion-MNIST está disponible como un conjunto de datos con una llamada del API de TensorFlow. \n",
    "\n",
    "Simplemente declaramos un objeto de tipo MNIST cargándolo de la base de datos Keras. \n",
    "\n",
    "``` python\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "```\n",
    "\n",
    "En este objeto, si llamamos al método de carga de datos (`load_data()`), nos devolverá 4 listas:\n",
    "- Los datos de entrenamiento, \n",
    "- las etiquetas de entrenamiento, \n",
    "- los datos de prueba y \n",
    "- las etiquetas de prueba. \n",
    "\n",
    "¿Cuáles son estas podrías preguntar? Cuando se construye una red neuronal como esta, es una buena estrategia usar algunos de tus datos para entrenar la red neuronal y datos similares que el modelo aún no ha visto para probar lo buena que es reconociendo imágenes. En el conjunto de datos Fashion MNIST, 60.000 de las 70.000 imágenes son usadas para entrenar la red, y entonces 10.000 imágenes, unas que no ha visto previamente pueden ser usadas para probar lo bien o mal que lo está realizando. Este código te dará esos conjuntos. Cada conjunto tiene datos, las imágenes mismas y las etiquetas, y eso es lo que la imagen es en realidad. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/01.jpg\", style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n",
    "Entonces, por ejemplo, los datos de entrenamiento contendrán imágenes como esta, y una etiqueta que describe la imagen así. Esta imagen es un botín, la etiqueta que la describe es el número 9. ¿Por qué crees que podría ser? Existen dos razones principales. \n",
    "- Primero, por supuesto, es que las computadoras son mejores con números que con textos. \n",
    "- Segundo, muy importante, es que esto es algo que nos puede ayudar a reducir sesgos. Si lo etiquetáramos como un botín, por supuesto, estaríamos sesgando hacia los anglo parlantes. Pero al ser una etiqueta numérica, podemos referirnos a ello en nuestro propio lenguaje sea inglés, chino, japones o incluso gaélico irlandés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The structure of Fashion MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí has visto cómo los datos pueden cargarse en estructuras de datos de Python que facilitan el entrenamiento de una red neuronal. Has visto cómo la imagen se representa como una matriz de 28x28 escalas de grises, y cómo su etiqueta es un número. El uso de un número es un primer paso para evitar el sesgo, en lugar de etiquetarlo con palabras en un idioma específico y excluir a las personas que no hablan ese idioma. Puede obtener más información sobre el sesgo y las técnicas para evitarlo [aquí](https://developers.google.com/machine-learning/fairness-overview/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding a Computer Vision Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veremos el código para la definición de una red neuronal. Recuerda que la última vez teníamos sequential con una sola capa en ella. Ahora tenemos 3 capas. \n",
    "\n",
    "``` python\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "```\n",
    "\n",
    "Las cosas importantes a mirar son la primera y última capas:\n",
    "- La última capa tiene 10 neuronas porque tenemos 10 clases de ropa en el conjunto de datos. Esto debe siempre coincidir. \n",
    "- La primera capa es una capa flatten con la forma de entrada de 28 por 28. Si recuerdas, nuestras imágenes son de 28 por 28, estamos especificando que esta es la forma en que debemos esperar los datos de entrada. Flatten toma este cuadrado de 28 por 28 y lo transforma en un vector lineal simple. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/C1_W2_Página_09.jpg\", style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n",
    "Lo interesante pasa en la capa intermedia, muchas veces llamada también **capa oculta**. Esta tiene 128 neuronas me gustaría que piensen en ellas como variables en una función. Quizás $x_1$, $x_2$, $x_3$, etc. Existe una regla que incorpora todo esto, que convierte los 784 valores de un botín en el valor 9, y similarmente para todos los otros 70.000. Es una función muy compleja de ver mapeando las imágenes tú mismo, pero eso es lo que hace una red neuronal. \n",
    "\n",
    "Por ejemplo si dices la función y es igual a $w0x0 + w1x1 + w2x2 + w3x3 + ... + w128x128$. Hallando los valores de $w$, entonces y dará 9, cuando tienes el valor de entrada del zapato. Verás que está haciendo algo muy, muy similar a lo que hicimos anteriormente cuando hallamos $y=2x-1$. En este caso el 2, era el peso de $x$. Estoy diciendo que $y=w1x1$, etc. \n",
    "\n",
    "No te preocupes si esto no está muy claro en este momento. Con el tiempo lo dominarás, viendo que funciona, hay algunas herramientas que te permitirán mirar dentro para ver lo que está sucediendo. Lo importante por ahora es que el código funcione, para que veas un escenario de clasificación por ti mismo. También puedes modificar la red neuronal añadiendo, eliminando y cambiando el tamaño de la capa para ver el impacto. Lo harás en el siguiente ejercicio. \n",
    "\n",
    "Asimismo, si deseas ir más allá, revisa este tutorial de Andrew en [Youtube](https://youtu.be/fXOsFF95ifk), que aclarará cómo las capas densamente conectadas funcionan desde las perspectivas teórica y matemática. Pero por ahora, volvamos al código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how it's done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente vídeo, Laurence te guiará por un cuaderno de trabajo en el que podrás ver cómo se entrena una red neuronal con imágenes de moda. Después podrás probar el libro de trabajo por ti mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk through a Notebook for computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acabas de ver cómo crear una red neuronal que da capacidades de visión por computadora básicas para reconocer diferentes artículos de ropa. Trabajemos ahora con un cuaderno que tiene todo el código para hacer eso. Luego verás el cuaderno tú mismo y si quieres puedes hacer algunos ejercicios. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/02.jpg\", style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "Empecemos importando TensorFlow. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/03.jpg\", style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "Voy a obtener los datos de Fashion MNIST usando `tf.keras.datasets`. Llamando al método `load_data`, Obtengo los datos de entrenamiento y las etiquetas así como los datos de prueba y las etiquetas. Para más detalles sobre esto, vuelve a revisar el anterior vídeo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/04.jpg\", style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "Los datos de una imagen en particular es una cuadrícula de valores desde cero hasta 255 con valores de los píxeles en escala de grises. Usando matplotlib, puedo dibujarlos como una imagen para facilitar la inspección. También puedo imprimir los valores en bruto para que podamos ver qué aspecto tienen. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"left\", src=\"./imagenes/05.jpg\", style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/06.jpg\", style=\"width:50%;\" >\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes ver los valores en bruto de los números de píxel de cero a 255, y puedes observar la imagen real. \n",
    "\n",
    "Esto fue para la primera imagen en el vector. Echemos un vistazo a la imagen en el índice 42 en su lugar, y podemos ver los diferentes valores de los píxeles y la gráfica real. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/07.jpg\", style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "Nuestra imagen tiene valores de cero a 255, pero las redes neuronales funcionan mejor con datos normalizados. Vamos a cambiarlos a valores entre cero y uno simplemente dividiendo cada valor por 255. En Python puedes realmente dividir un vector entero con una línea de código así. Ahora diseñamos nuestro modelo. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/08.jpg\", style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "Como explicamos anteriormente:\n",
    "- hay una capa de entrada con la forma de los datos y \n",
    "- una capa de salida con la forma de las clases, y \n",
    "- una capa oculta que trata de hallar las reglas entre ellas. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/09.jpg\", style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "Compilamos el modelo para encontrar la función de pérdida y el optimizador, y el objetivo de estos es como antes, hacer una conjetura de cuál es la relación entre los datos de entrada y los datos de salida, medir lo bien o lo mal que lo hacen mediante la función de pérdida, usa el optimizador para generar una nueva conjetura y repite. Podemos tratar de ajustar las imágenes de entrenamiento a las etiquetas de entrenamiento. Lo haremos solo durante cinco epochs para ser breves. \n",
    "\n",
    "Pasamos unos 25 segundos entrenándolo durante cinco epochs y terminamos con una pérdida de cerca de 0.29. Eso significa que es bastante preciso en conjeturar la relación entre las imágenes y las etiquetas. No es genial!. Pero ten en cuenta que se ha hecho en solo 25 segundos con una red neuronal muy básica, lo que no está tampoco mal. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/10.jpg\", style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "Pero una mejor medida del rendimiento se puede ver probando los datos de prueba. Estas son imágenes que la red aún no ha visto. Esperarías que el rendimiento fuera peor, pero si es aún peor, tienes un problema. Como puedes ver es alrededor de 0.345 de pérdida, lo que significa que es un poco menos preciso en el conjunto de prueba. No es tampoco genial, pero sabemos que estamos haciendo algo bien. \n",
    "\n",
    "Tu trabajo ahora consiste en mirar el cuaderno, intentar los ejercicios y ver si cambiando los parámetros en la red neuronal o cambiando las epochs, hay alguna forma de obtener unos 0.71 de pérdida de precisión en los datos de entrenamiento y 0.66 de precisión en los de prueba, pruébalo tú mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get hands-on with computer vision (Lab 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que has visto el cuaderno de trabajo, es el momento de probarlo por ti mismo.  Puede encontrarlo [aquí la versión original](https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/main/C1/W2/ungraded_labs/C1_W2_Lab_1_beyond_hello_world.ipynb). También hemos incluido una serie de ejercicios que puedes probar al final del libro de trabajo. Estos ejercicios te ayudarán a experimentar con el código y te ayudarán con el código que tendrás que escribir al final de la semana, así que vale la pena dedicarles algo de tiempo. Te recomiendo que dediques al menos 1 hora a jugar con este cuaderno. Merece la pena dedicarle tiempo.\n",
    "\n",
    "Cuando hayas terminado con eso, lo siguiente es explorar las devoluciones de llamada. Una de las cosas que puedes hacer con eso es entrenar una red neuronal hasta que alcance un umbral que desees, y luego dejar de entrenar. Lo verás en el siguiente vídeo.\n",
    "\n",
    "> El Laboratorio en español se pueden encontrar\n",
    "> [aqui](https://github.com/IngCarlaPezzone/tensorflow-1-public/blob/main/C1/W2/ungraded_labs/C1_W2_Lab_1_beyond_hello_world_traducida.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Callbacks to control training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una pregunta que me hacen a menudo en este punto los programadores en particular cuando experimentan con diferentes números de epochs es ¿Cómo puedo parar el entrenamiento cuando alcanzo el punto en el que deseo estar? ¿Por qué siempre debo programar directamente un cierto número de epochs? La buena nueva es que el bucle de entrenamiento soporta **Callbacks**. En cada epoch, se puede retrollamar a una función de código, tras haber comprobado las métricas. Si son lo que quieres, entonces puedes cancelar el entrenamiento en ese punto. Echemos un vistazo. \n",
    "\n",
    "``` python\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epoch=5)\n",
    "```\n",
    "\n",
    "Este es nuestro código para entrenar la red neuronal para reconocer las imágenes de moda. En particular, mantén un ojo en la función `model.fit` que ejecuta el bucle de entrenamiento. Puedes ver eso aquí. \n",
    "\n",
    "Lo que haremos ahora es escribir una Callback en Python. Este es el código. \n",
    "\n",
    "``` python\n",
    "class myCallback(tf.keras.callback.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss')<0.4):\n",
    "            print(\"\\nLoss is low so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "```\n",
    "\n",
    "Está implementada como una clase separada, pero puede estar en línea con el otro código. No necesita estar en un archivo separado. En ella, implementaremos la función `on_epoch_end function`, que es llamada por la retrollamada cada vez que un epoch termina. \n",
    "\n",
    "También envía un objeto de registro que contiene mucha información importante sobre el estado actual del entrenamiento. Por ejemplo, la pérdida actual está disponible en los registros (`logs`), podemos consultarlo hasta cierto valor. Por ejemplo, aquí estoy comprobando si la pérdida es menor que 0.4 para cancelar el propio entrenamiento. \n",
    "\n",
    "Ahora que tenemos la retrollamada volvamos al resto del código, hay dos modificaciones que debemos hacer. Primero, instanciamos la clase que acabamos de crear, lo hacemos con este código. En model.fit, usé los parámetros de la retrollamada y paso esta instancia de la clase. \n",
    "\n",
    "``` python\n",
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epoch=5, callbacks=[callbacks])\n",
    "```\n",
    "Veamos esto en acción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how to implement Callbacks (Lab 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenta con el uso de Callbacks en este [cuaderno original](https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/main/C1/W2/ungraded_labs/C1_W2_Lab_2_callbacks.ipynb) -- ¡trabaja en él para ver cómo se desempeñan! \n",
    "\n",
    "> El Laboratorio en español se pueden encontrar\n",
    "> [aqui](https://github.com/IngCarlaPezzone/tensorflow-1-public/blob/main/C1/W2/ungraded_labs/C1_W2_Lab_2_callbacks_traducida.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk through a notebook with Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echemos un vistazo al código de las retrollamadas y veamos cómo funciona. Puedes ver el código aquí. \n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/11.jpg\", style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "Este es el cuaderno con el código ya escrito, y esta es la clase que definimos para el manejo de la retrollamada, y aquí es donde instanciamos la clase callback misma. Finalmente, aquí es donde configuramos la retrollamada como parte del bucle de entrenamiento. Cuando empezamos a entrenar, note que hemos pedido entrenar durante 5 epochs. Vigila las pérdidas que entrena.\n",
    "\n",
    "<figure>\n",
    " <img align=\"right\", src=\"./imagenes/12.jpg\", style=\"width:60%;\" >\n",
    "</figure>\n",
    "\n",
    "Deseamos que termine cuando sea más baja que 0.4 al final del primer epoch ya nos estamos acercando. Al iniciar el segundo epoch ya ha caído por debajo de 0.4, pero la retrollamada no ha sido alcanzada aún. Esto se debe a que se ha configurado para que sea al final del epoch. Hacer esto es una buena práctica, porque con algunos datos y algunos algoritmos, la pérdida puede variar arriba y abajo durante el epoch, porque todos los datos aún no han sido procesados. Prefiero esperar hasta el final para estar seguro. \n",
    "\n",
    "Ahora la época ha terminado, la pérdida es 0.3563, podemos ver que el entrenamiento termina, a pesar que solo hemos hecho dos epochs. Ten en cuenta que estamos seguros de que pedimos cinco epochs y que hemos terminado después de dos, porque la pérdida es menor que 0.4, que es lo que comprobamos en la retrollamada. Está muy bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 2 Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 1 </b></font>\n",
    "\n",
    "¿Cuál es la resolución de las 70.000 imágenes del conjunto de datos Fashion MNIST?\n",
    "\n",
    "- 28x28 Escala de grises\n",
    "- 100x100 Color\n",
    "- 28x28 Color\n",
    "- 82x82 Escala de grises\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 2 </b></font>\n",
    "\n",
    "¿Por qué hay 10 neuronas de salida en la red neuronal utilizada como ejemplo para el problema de visión por ordenador?\n",
    "\n",
    "- Para que se entrene 10 veces más rápido\n",
    "- Hay 10 etiquetas diferentes\n",
    "- Puramente arbitrario\n",
    "- Para que clasifique 10 veces más rápido\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 3 </b></font>\n",
    "\n",
    "¿Qué hace Relu?\n",
    "\n",
    "- Devuelve el negativo de x\n",
    "- Sólo devuelve x si x es mayor que cero\n",
    "- Para un valor x, devuelve 1/x\n",
    "- Sólo devuelve x si x es menor que cero\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 4 </b></font>\n",
    "\n",
    "¿Por qué se dividen los datos en conjuntos de entrenamiento y de prueba?\n",
    "\n",
    "- Para que las pruebas sean más rápidas\n",
    "- Para que el entrenamiento sea más rápido\n",
    "- Para entrenar una red con datos no vistos anteriormente\n",
    "- Para probar una red con datos no vistos anteriormente\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 5 </b></font>\n",
    "\n",
    "Verdadero o Falso: La función on_epoch_end envía un objeto logs con mucha información sobre el estado actual del entrenamiento al inicio de cada época.\n",
    "\n",
    "<font size=\"2\" color=\"red\"><b> PREGUNTA 6 </b></font>\n",
    "\n",
    "¿Por qué se establece el parámetro callbacks= en la función de ajuste?\n",
    "\n",
    "- Para que los bucles de entrenamiento realicen todas las épocas\n",
    "- Porque acelera el entrenamiento\n",
    "- Para que en cada epoch se pueda llamar a una función de código\n",
    "\n",
    "***\n",
    "\n",
    "<details>\n",
    "   <summary><font size=\"2\" color=\"darkblue\"><b> Click para la respuesta</b></font></summary>\n",
    "\n",
    "Respuesta 1:\n",
    "    \n",
    "Respuesta 2: Verdadero.\n",
    "  \n",
    "Respuesta 3:\n",
    "    \n",
    "Respuesta 4:\n",
    "    \n",
    "Respuesta 5:\n",
    "    \n",
    "Respuesta 6:\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEEKLY ASSIGNMENT - IMPLEMENT A DEEP NEURAL NETWORK TO RECOGNIZE HANDWRITTEN DIGITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El Laboratorio en español se pueden encontrar\n",
    "> [aqui](https://github.com/IngCarlaPezzone/tensorflow-1-public/blob/main/C1/W2/assignment/C1W2_Assignment_traducida.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
