{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"YuSYVbwEYNHw"},"source":["# Laboratorio no calificado: Análisis de modelos TensorFlow\n","\n","En los sistemas de producción, la decisión de desplegar un modelo suele ir más allá de las métricas globales (por ejemplo, la precisión) establecidas durante el entrenamiento. También es importante evaluar el rendimiento del modelo en diferentes escenarios. Por ejemplo, ¿su modelo de previsión meteorológica funciona igual de bien en verano que en invierno? ¿O su detector de defectos basado en cámaras sólo funciona en determinadas condiciones de iluminación? Este tipo de investigación ayuda a garantizar que su modelo puede manejar distintos casos. Más que eso, puede ayudar a descubrir cualquier sesgo aprendido que pueda resultar en una experiencia negativa para sus usuarios. Por ejemplo, si se supone que tienes una aplicación de género neutro, no querrás que tu modelo sólo funcione bien para uno y mal para otro.\n","\n","En este laboratorio, estarás trabajando con [TensorFlow Model Analysis (TFMA)](https://www.tensorflow.org/tfx/guide/tfma) -- una librería construida específicamente para analizar el rendimiento de un modelo a través de diferentes configuraciones. Te permite especificar porciones de tus datos, luego calculará y visualizará cómo se desempeña tu modelo en cada porción. También puede establecer umbrales que su modelo debe cumplir antes de que se marque como listo para su despliegue. Esto le ayudará a tomar mejores decisiones sobre cualquier mejora que desee realizar para aumentar el rendimiento de su modelo y garantizar la equidad.\n","\n","En este ejercicio, utilizará TFMA para analizar modelos entrenados en el conjunto de datos [Census Income dataset](http://archive.ics.uci.edu/ml/datasets/Census+Income). En concreto, deberá:\n","\n","* estudiará y configurará los archivos de inicio para utilizarlos con TFMA\n","* crear un archivo de configuración para indicar a TFMA los datos que analizará y las métricas que calculará\n","* Visualizar los resultados de TFMA en un entorno de cuaderno.\n","* generar una serie temporal del rendimiento de un modelo\n","* Comparar el rendimiento de dos modelos para decidir cuál poner en producción.\n","\n","*Créditos: Parte del código y las discusiones se basan en el [tutorial oficial] del equipo TensorFlow (https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic)."]},{"cell_type":"markdown","metadata":{"id":"VUHcOxH0W2PH"},"source":["## Setup\n","\n","En esta sección, primero configurará su espacio de trabajo para tener todos los módulos y archivos para trabajar con TFMA. Deberás \n","* Instalar las bibliotecas necesarias, \n","* Descargará los archivos de inicio que contendrán el conjunto de datos, el esquema y los modelos preentrenados que analizará.\n","* Preparar el conjunto de datos para que pueda ser consumido por TFMA.\n","* Observará cómo los modelos transforman las características en bruto."]},{"cell_type":"markdown","metadata":{"id":"q7-ouHFnWAsu"},"source":["### Instalar extensiones Jupyter\n","Si se ejecuta en un cuaderno Jupyter local, entonces estas extensiones Jupyter deben ser instaladas en el entorno antes de ejecutar Jupyter. Éstas ya están disponibles en Colab, por lo que dejaremos aquí los comandos como referencia.\n","\n","```bash\n","jupyter nbextension enable --py widgetsnbextension --sys-prefix \n","jupyter nbextension install --py --symlink tensorflow_model_analysis --sys-prefix \n","jupyter nbextension enable --py tensorflow_model_analysis --sys-prefix \n","```"]},{"cell_type":"markdown","metadata":{"id":"LZj-impiAD_l"},"source":["### Instalar bibliotecas\n","\n","Esto instalará todas las dependencias y tardará entre 6 y 8 minutos en completarse.\n"]},{"cell_type":"code","metadata":{"id":"8X32Q_lIKYxH"},"source":["# Upgrade pip to the latest version and install required packages\n","!pip install -U pip\n","!pip install --use-deprecated=legacy-resolver tensorflow_data_validation==1.1.0\n","!pip install --use-deprecated=legacy-resolver tensorflow-transform==1.0.0\n","!pip install --use-deprecated=legacy-resolver tensorflow-model-analysis==0.32.0\n","!pip install apache-beam==2.32.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k7121_u1LO5W"},"source":["*Nota: En Google Colab, es necesario reiniciar el tiempo de ejecución en este punto para finalizar la actualización de los paquetes que acaba de instalar. **Por favor, no continúe con la siguiente sección sin reiniciar.** También puede ignorar los errores sobre la incompatibilidad de versiones de algunos de los paquetes incluidos, ya que no vamos a utilizarlos en este cuaderno."]},{"cell_type":"markdown","metadata":{"id":"saT03A81Z4Nr"},"source":["### Comprobar la instalación\n","\n","Ejecutando el código de abajo debería mostrar las versiones de los paquetes. Por favor, vuelve a ejecutar la instalación si ves errores y no olvides reiniciar el runtime después de la reinstalación."]},{"cell_type":"code","metadata":{"id":"SA2E343NAMRF"},"source":["# Import packages and print versions\n","import tensorflow as tf\n","import tensorflow_model_analysis as tfma\n","import tensorflow_data_validation as tfdv\n","\n","print('TF version: {}'.format(tf.__version__))\n","print('TFMA version: {}'.format(tfma.__version__))\n","print('TFDV version: {}'.format(tfdv.__version__))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RptgLn2RYuK3"},"source":["### Cargar los archivos\n","\n","A continuación, descargará los archivos que necesitará para este ejercicio:\n","\n","* Conjuntos de datos de prueba\n","* Esquema de datos\n","* Modelos preentrenados\n","\n","También hemos definido algunas variables globales a continuación para que puedas acceder a estos archivos a lo largo del cuaderno más fácilmente."]},{"cell_type":"code","metadata":{"id":"K4QXVIM7iglN"},"source":["import os\n","\n","# String variables for file and directory names\n","URL = 'https://storage.googleapis.com/mlep-public/course_3/week4/C3_W4_Lab_1_starter_files.tar.gz'\n","TAR_NAME = 'C3_W4_Lab_1_starter_files.tar.gz'\n","BASE_DIR = 'starter_files'\n","DATA_DIR = os.path.join(BASE_DIR, 'data')\n","CSV_DIR = os.path.join(DATA_DIR, 'csv')\n","TFRECORD_DIR = os.path.join(DATA_DIR, 'tfrecord')\n","MODELS_DIR = os.path.join(BASE_DIR, 'models')\n","SCHEMA_FILE = os.path.join(BASE_DIR, 'schema.pbtxt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mw6d-3aNw-fm"},"source":["# descomente esta línea si ha descargado los archivos antes y desea restablecerlos\n","# !rm -rf {BASE_DIR}\n","\n","# Download the tar file from GCP\n","!wget {URL}\n","\n","# Extract the tar file to the base directory\n","!tar xzf {TAR_NAME}\n","\n","# Delete tar file\n","!rm {TAR_NAME}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wrO1e6QnVf9I"},"source":["Puede ver los archivos y directorios de nivel superior ejecutando la celda que aparece a continuación (o simplemente utilizando el explorador de archivos situado en la parte izquierda de este Colab). Discutiremos lo que contiene cada uno en las siguientes secciones."]},{"cell_type":"code","metadata":{"id":"NpNZrJl-YJq9"},"source":["print(\"Here's what we downloaded:\")\n","!ls {BASE_DIR}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UBhvex2jSBa_"},"source":["### Vista previa del conjunto de datos"]},{"cell_type":"markdown","metadata":{"id":"iIxhCtvaV0cC"},"source":["El directorio `data/csv` contiene la división de prueba del conjunto de datos Census Income. Lo hemos dividido en varios archivos para este cuaderno de demostración:\n","\n","* Datos_prueba.csv: 15.000 filas de datos de prueba.\n","* datos_prueba_1.csv` - primeras 5000 filas de datos_prueba.csv\n","* datos_prueba_2.csv` - las siguientes 5000 filas de datos_prueba.csv\n","* Datos_prueba_3.csv - últimas 5000 filas de Datos_prueba.csv\n","\n","Puede ver la descripción de cada columna [aquí](http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names) (por favor, abra el enlace en una ventana nueva si Colab impide la descarga). Además, para simplificar, ya hemos preprocesado la columna `label` como binaria (es decir, `0` o `1`) para que coincida con la salida del modelo. En sus propios proyectos, las etiquetas pueden ser de un tipo de datos diferente (por ejemplo, cadena) y desea transformar primero para que pueda evaluar su modelo correctamente. Puede previsualizar las primeras filas a continuación:"]},{"cell_type":"code","metadata":{"id":"C4LCdt9zQ1oL"},"source":["# Path to the full test set\n","TEST_DATA_PATH = os.path.join(CSV_DIR, 'data_test.csv')\n","\n","# Preview the first few rows\n","!head {TEST_DATA_PATH}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_xa7ZDV1MycO"},"source":["### Parsear el Esquema\n","\n","También ha descargado un esquema generado por [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/). Ya deberías estar familiarizado con este tipo de archivo de cursos anteriores. Lo cargarás ahora para poder utilizarlo en las partes posteriores del cuaderno."]},{"cell_type":"code","metadata":{"id":"XYo2SHFzf6_t"},"source":["# Load the schema as a protocol buffer\n","SCHEMA = tfdv.load_schema_text(SCHEMA_FILE)\n","\n","# Display the schema\n","tfdv.display_schema(SCHEMA)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UP3yuJxfNXRL"},"source":["### Utilizar el esquema para crear TFRecords\n","\n","TFMA necesita un archivo TFRecord de entrada, por lo que necesitas convertir los CSVs en el directorio de datos. Si has hecho los laboratorios anteriores, sabrás que esto se puede hacer fácilmente con `ExampleGen`. Para este cuaderno, sin embargo, se utilizará la función de ayuda a continuación para demostrar cómo se puede hacer fuera de una tubería TFX. Pasarás el esquema que cargaste en el paso anterior para determinar el tipo correcto de cada característica."]},{"cell_type":"code","metadata":{"id":"8-wud3fPczl6"},"source":["# imports for helper function\n","import csv\n","from tensorflow.core.example import example_pb2\n","from tensorflow_metadata.proto.v0 import schema_pb2\n","\n","def csv_to_tfrecord(schema, csv_file, tfrecord_file):\n","  ''' Convierte un archivo csv en un tfrecord\n","  Args:\n","    schema (schema_pb2) - protobuf de esquema de TFDV\n","    csv_file (cadena) - archivo a convertir en tfrecord\n","    tfrecord_file (cadena) - nombre del archivo tfrecord a crear\n","\n","  Devuelve\n","    nombre de archivo de tfrecord\n","  '''\n","\n","  # Abrir archivo CSV para su lectura. Cada fila se mapea como un diccionario.\n","  reader = csv.DictReader(open(csv_file, 'r'))\n","  \n","  # Inicializar la lista de ejemplos de TF\n","  examples = []\n","\n","  # Para cada fila en CSV, crear un Ejemplo TF basado en\n","  # el esquema y añádalo a la lista\n","  for line in reader:\n","\n","    # Intialize example\n","    example = example_pb2.Example()\n","\n","    # Bucle a través de características en el esquema\n","    for feature in schema.feature:\n","\n","      # Obtener el nombre de la característica actual\n","      key = feature.name\n","\n","      # Rellenar valores según el tipo de datos de la entidad actual\n","      if feature.type == schema_pb2.FLOAT:\n","        example.features.feature[key].float_list.value[:] = (\n","            [float(line[key])] if len(line[key]) > 0 else [])\n","      elif feature.type == schema_pb2.INT:\n","        example.features.feature[key].int64_list.value[:] = (\n","            [int(line[key])] if len(line[key]) > 0 else [])\n","      elif feature.type == schema_pb2.BYTES:\n","        example.features.feature[key].bytes_list.value[:] = (\n","            [line[key].encode('utf8')] if len(line[key]) > 0 else [])\n","        \n","    # Append to the list\n","    examples.append(example)\n","\n","  # Escribir ejemplos en el archivo tfrecord\n","  with tf.io.TFRecordWriter(tfrecord_file) as writer:\n","    for example in examples:\n","      writer.write(example.SerializeToString())\n","  \n","  return tfrecord_file"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sSO1fOrrYZjK"},"source":["El siguiente código hará la conversión y hemos definido algunas variables globales más que usará en ejercicios posteriores."]},{"cell_type":"code","metadata":{"id":"xU8R41EexIoc"},"source":["# Create tfrecord directory\n","!mkdir {TFRECORD_DIR}\n","\n","# Create list of tfrecord files\n","tfrecord_files = [csv_to_tfrecord(SCHEMA, f'{CSV_DIR}/{name}', f\"{TFRECORD_DIR}/{name.replace('csv','tfrecord')}\") \n","  for name in os.listdir(CSV_DIR)]\n","\n","# Print created files\n","print(f'files created: {tfrecord_files}')\n","\n","# Create variables for each tfrecord\n","TFRECORD_FULL = os.path.join(TFRECORD_DIR, 'data_test.tfrecord')\n","TFRECORD_DAY1 = os.path.join(TFRECORD_DIR, 'data_test_1.tfrecord')\n","TFRECORD_DAY2 = os.path.join(TFRECORD_DIR, 'data_test_2.tfrecord')\n","TFRECORD_DAY3 = os.path.join(TFRECORD_DIR, 'data_test_3.tfrecord')\n","\n","# Delete unneeded variable\n","del tfrecord_files"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wr6d8JqzR8TZ"},"source":["### Modelos preentrenados\n","\n","Por último, también has descargado modelos Keras preentrenados y están almacenados en el directorio `models/`. TFMA soporta diferentes tipos de modelos, incluyendo modelos TF Keras, modelos basados en APIs genéricas de firmas TF2, así como modelos basados en estimadores TF. La guía [get_started](https://www.tensorflow.org/tfx/model_analysis/get_started) contiene la lista completa de tipos de modelos soportados y sus restricciones. También puede consultar las [FAQ](https://www.tensorflow.org/tfx/model_analysis/faq) para ver ejemplos sobre cómo configurar estos modelos.\n","\n","Hemos incluido tres modelos y puede elegir analizar cualquiera de ellos en las secciones posteriores. Se han guardado en formato [SavedModel](https://www.tensorflow.org/guide/saved_model) que es el predeterminado cuando se guarda con la API de modelos de Keras."]},{"cell_type":"code","metadata":{"id":"HQ4mjuMkR7z2"},"source":["# list model directories\n","!ls {MODELS_DIR}\n","\n","# Create string variables for each model directory\n","MODEL1_FILE = os.path.join(MODELS_DIR, 'model1')\n","MODEL2_FILE = os.path.join(MODELS_DIR, 'model2')\n","MODEL3_FILE = os.path.join(MODELS_DIR, 'model3')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x0eQ0M7BI6IG"},"source":["Como ya se ha mencionado, estos modelos se entrenaron con el conjunto de datos [Census Income dataset](http://archive.ics.uci.edu/ml/datasets/Census+Income). La etiqueta es `1` si una persona gana más de 50.000 USD y `0` si gana menos o igual. Puede cargar uno de los modelos y consultar el resumen para hacerse una idea de su arquitectura. Los tres modelos utilizan la misma arquitectura, pero se entrenaron con diferentes épocas para simular un rendimiento variable."]},{"cell_type":"code","metadata":{"id":"vvIEhxeMxekr"},"source":["# Load model 1\n","model = tf.keras.models.load_model(MODEL1_FILE)\n","\n","# Print summary. You can ignore the warnings at the start.\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L8P-3h-HLPtH"},"source":["Puedes ver el código para construir estos en el próximo laboratorio. Por ahora, sólo tendrá que tomar nota de algunas cosas. En primer lugar, la salida es una sola unidad densa con una activación sigmoide (es decir, `denso_5` arriba). Esto es estándar para problemas de clasificación binaria.\n","\n","Otra es que el modelo se exporta con una capa de transformación. Esto se puede ver en el resumen de arriba en la fila inferior llamada `transform_features_layer` y no está conectada a las otras capas. De laboratorios anteriores, usted sabrá que esto se toma de la gráfica generada por el componente `Transform`. Ayuda a evitar sesgos en el entrenamiento asegurándose de que las entradas brutas se transforman de la misma manera que el modelo espera. También está disponible como propiedad `tft_layer` del objeto modelo."]},{"cell_type":"code","metadata":{"id":"qjEsamx6620d"},"source":["# Se puede acceder a la capa de transformación de dos maneras. Estos son equivalentes.\n","model.get_layer('transform_features_layer') is model.tft_layer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cvzrnszr9YL1"},"source":["TFMA invoca esta capa automáticamente para sus entradas brutas, pero hemos incluido un breve fragmento a continuación para demostrar cómo funciona la transformación. Puede ver que las características brutas se reformatean para que sean aceptables para el modelo. Las características numéricas en bruto se escalan y las características categóricas en bruto (cadena) se codifican en vectores de un solo golpe."]},{"cell_type":"code","metadata":{"id":"pIUo4v_NFBuO"},"source":["from tensorflow_transform.tf_metadata import schema_utils\n","\n","# Load one tfrecord\n","tfrecord_file = tf.data.TFRecordDataset(TFRECORD_DAY1)\n","\n","# Parse schema object as a feature spec\n","feature_spec = schema_utils.schema_as_feature_spec(SCHEMA).feature_spec\n","\n","# Create a batch from the dataset\n","for records in tfrecord_file.batch(1).take(1):\n","\n","  # Parse the batch to get a dictionary of raw features\n","  parsed_examples = tf.io.parse_example(records, feature_spec)\n","\n","  # Print the results\n","  print(\"\\nRAW FEATURES:\")\n","  for key, value in parsed_examples.items():\n","    print(f'{key}: {value.numpy()}')\n","  \n","  # Pop the label since the model does not expect a label input\n","  parsed_examples.pop('label')\n","\n","  # Transform the rest of the raw features using the transform layer\n","  transformed_examples = model.tft_layer(parsed_examples)\n","\n","  # Print the input to the model\n","  print(\"\\nTRANSFORMED FEATURES:\")\n","  for key, value in transformed_examples.items():\n","    print(f'{key}: {value.numpy()}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AEeCIAwXJnDr"},"source":["Las características transformadas pueden introducirse en el modelo para obtener las predicciones. El siguiente fragmento de código lo demuestra y utilizamos una métrica de bajo umbral [BinaryAccuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryAccuracy) para comparar las etiquetas verdaderas y las predicciones del modelo."]},{"cell_type":"code","metadata":{"id":"FXIrFLKPyHtz"},"source":["from tensorflow_transform.tf_metadata import schema_utils\n","\n","# Load one tfrecord\n","tfrecord_file = tf.data.TFRecordDataset(TFRECORD_DAY1)\n","\n","# Parse schema object as a feature spec\n","feature_spec = schema_utils.schema_as_feature_spec(SCHEMA).feature_spec\n","\n","# Create a batch from the dataset\n","for records in tfrecord_file.batch(5).take(1):\n","\n","  # Get the label values from the raw input\n","  parsed_examples = tf.io.parse_example(records, feature_spec)\n","  y_true = parsed_examples.pop('label')\n","  print(f'labels:\\n {y_true.numpy()}\\n')\n","  \n","  # Transform the raw features and pass to the model to get predictions\n","  transformed_examples = model.tft_layer(parsed_examples)\n","  y_pred = model(transformed_examples)\n","  print(f'predictions:\\n {y_pred.numpy()}\\n')\n","  \n","  # Measure the binary accuracy\n","  metric = tf.keras.metrics.BinaryAccuracy(threshold=0.3)\n","  metric.update_state(y_true, y_pred)\n","  print(f'binary accuracy: {metric.result().numpy()}\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MGFEc_P0LH8b"},"source":["La última cosa a tener en cuenta es que el modelo también se exporta con una [serving signature](https://www.tensorflow.org/guide/saved_model#specifying_signatures_during_export). Usted sabrá más acerca de esto en el próximo laboratorio y en las partes posteriores de la especialización, pero por ahora, usted puede pensar en ello como una configuración para cuando el modelo se despliega para la inferencia. Para este modelo en particular, la firma por defecto está configurado para transformar los lotes de características en bruto serializados antes de alimentar a la entrada del modelo. De esta manera, usted no tendría que codificar explícitamente las transformaciones como se muestra en el fragmento anterior. Usted puede simplemente pasar en lotes de datos directamente como se muestra a continuación."]},{"cell_type":"code","metadata":{"id":"Nh9rvKbSUW_l"},"source":["# Load one tfrecord\n","tfrecord_file = tf.data.TFRecordDataset(TFRECORD_DAY1)\n","\n","# Print available signatures\n","print(f'model signatures: {model.signatures}\\n')\n","\n","# Create a batch\n","for records in tfrecord_file.batch(5).take(1):\n","\n","  # Pass the batch to the model serving signature to get predictions\n","  output = model.signatures['serving_default'](examples=records)\n","\n","  # Print results\n","  print(f\"predictions:\\n {output['output_0']}\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8gNoFWd3N-9b"},"source":["TFMA accede a esta firma de modelo para poder trabajar con los datos brutos y evaluar el modelo para obtener las métricas. No sólo eso, también puede extraer características específicas y valores de dominio de su conjunto de datos antes de calcular estas métricas. Veamos cómo se hace esto en la siguiente sección."]},{"cell_type":"markdown","metadata":{"id":"fp8Ub7GTXH3j"},"source":["## Configurar y ejecutar TFMA\n","\n","Con el conjunto de datos y el modelo ya disponibles, puede pasar a utilizar TFMA. Hay algunos pasos adicionales necesarios:\n","\n","* Crear un mensaje de protocolo `tfma.EvalConfig` que contenga detalles sobre los modelos, métricas y datos que desea analizar.\n","* Crear un `tfma.EvalSharedModel` que apunte a los modelos guardados.\n","* Especifique una ruta de salida donde se almacenarán los resultados del análisis. "]},{"cell_type":"markdown","metadata":{"id":"qgC7NdCatT8y"},"source":["###Crear EvalConfig\n","\n","El [tfma.EvalConfig()](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/EvalConfig?hl=nn&skip_cache=true) es un mensaje de protocolo que configura el análisis. Aquí se especifica:\n","\n","* [`model_specs`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/ModelSpec) - mensaje que contiene al menos la clave de la etiqueta para que pueda extraerse de los datos de la evaluación/prueba.\n","\n","* [`metrics_specs`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/MetricsSpec) - que contiene las métricas que desea evaluar. Puede encontrar una guía completa [aquí](https://www.tensorflow.org/tfx/model_analysis/metrics) y utilizará las métricas de clasificación binaria para este ejercicio.\n","\n","* [`slicing_specs`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/SlicingSpec) - contiene los cortes de características para los que desea calcular las métricas. Una breve descripción de los diferentes tipos de cortes se muestra [aquí](https://www.tensorflow.org/tfx/model_analysis/setup#slicing_specs)\n","\n","La configuración de la evaluación debe pasarse como un mensaje de protocolo y puedes utilizar el módulo [google.protobuf.text_format](https://googleapis.dev/python/protobuf/latest/google/protobuf/text_format.html) para ello, como se muestra a continuación."]},{"cell_type":"code","metadata":{"id":"PLJxcjpjfwkx"},"source":["import tensorflow_model_analysis as tfma\n","from google.protobuf import text_format\n","\n","# Setup tfma.EvalConfig settings\n","eval_config = text_format.Parse(\"\"\"\n","  ## Model information\n","  model_specs {\n","    # For keras (and serving models), you need to add a `label_key`.\n","    label_key: \"label\"\n","  }\n","\n","  ## Post training metric information. These will be merged with any built-in\n","  ## metrics from training.\n","  metrics_specs {\n","    metrics { class_name: \"ExampleCount\" }\n","    metrics { class_name: \"BinaryAccuracy\" }\n","    metrics { class_name: \"BinaryCrossentropy\" }\n","    metrics { class_name: \"AUC\" }\n","    metrics { class_name: \"AUCPrecisionRecall\" }\n","    metrics { class_name: \"Precision\" }\n","    metrics { class_name: \"Recall\" }\n","    metrics { class_name: \"MeanLabel\" }\n","    metrics { class_name: \"MeanPrediction\" }\n","    metrics { class_name: \"Calibration\" }\n","    metrics { class_name: \"CalibrationPlot\" }\n","    metrics { class_name: \"ConfusionMatrixPlot\" }\n","    # ... add additional metrics and plots ...\n","  }\n","\n","  ## Slicing information\n","\n","  # overall slice\n","  slicing_specs {}\n","\n","  # slice specific features\n","  slicing_specs {\n","    feature_keys: [\"sex\"]\n","  }\n","  slicing_specs {\n","    feature_keys: [\"race\"]\n","  }\n","\n","  # slice specific values from features\n","  slicing_specs {\n","    feature_values: {\n","      key: \"native-country\"\n","      value: \"Cambodia\"\n","    }\n","  }\n","  slicing_specs {\n","    feature_values: {\n","      key: \"native-country\"\n","      value: \"Canada\"\n","    }\n","  }\n","\n","  # slice feature crosses\n","  slicing_specs {\n","    feature_keys: [\"sex\", \"race\"]\n","  }\n","\"\"\", tfma.EvalConfig())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J165kzHNTEQN"},"source":["### Crear EvalSharedModel\n","\n","TFMA también requiere una instancia [EvalSharedModel](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/types/EvalSharedModel) que apunte a tu modelo para que pueda ser compartido entre múltiples hilos en el mismo proceso. Esta instancia incluye información sobre el tipo de modelo (keras, etc) y cómo cargar y configurar el modelo desde su ubicación guardada en disco (por ejemplo, etiquetas, etc). La API [tfma.default_eval_shared_model()](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/default_eval_shared_model) se puede utilizar para crear esto dada la ubicación del modelo y la configuración de la evaluación."]},{"cell_type":"code","metadata":{"id":"KsnjbIi5OtXb"},"source":["# Create a tfma.EvalSharedModel that points to your model.\n","# You can ignore the warnings generated.\n","eval_shared_model = tfma.default_eval_shared_model(\n","    eval_saved_model_path=MODEL1_FILE,\n","    eval_config=eval_config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F0s4wWgQb2LT"},"source":["# Show properties of EvalSharedModel\n","print(f'EvalSharedModel contents: {eval_shared_model}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pViNbIpuVYLU"},"source":["### Ejecutar TFMA\n","\n","Con la configuración completa, sólo tiene que declarar un directorio de salida y luego ejecutar TFMA. Pasará la configuración de evaluación, el modelo compartido, el conjunto de datos y el directorio de salida a [`tfma.run_model_analysis()`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/run_model_analysis) como se muestra a continuación. Esto creará un [`tfma.EvalResult`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/EvalResult) que puede utilizar más tarde para la representación de métricas y gráficos."]},{"cell_type":"code","metadata":{"id":"P3ej6jgiVkuY"},"source":["# Specify output path for the evaluation results\n","OUTPUT_DIR = os.path.join(BASE_DIR, 'output')\n","\n","# Run TFMA. You can ignore the warnings generated.\n","eval_result = tfma.run_model_analysis(\n","    eval_shared_model=eval_shared_model,\n","    eval_config=eval_config,\n","    data_location=TFRECORD_FULL,\n","    output_path=OUTPUT_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A0khNBC9FlEO"},"source":["## Visualización de métricas y gráficos\n","\n","También puede visualizar los resultados utilizando los métodos TFMA. En esta sección, verá las métricas y gráficos devueltos para los diferentes cortes especificados en la configuración de evaluación."]},{"cell_type":"markdown","metadata":{"id":"cSl9qyTCbBKR"},"source":["### Renderización de métricas\n","\n","Puede ver las métricas con el método [`tfma.view.render_slicing_metrics()`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/view/render_slicing_metrics). Por defecto, las vistas mostrarán el corte `Overall`. Para ver una porción en particular puede pasar un nombre de característica al argumento `slicing_column` como se muestra a continuación. Puede visualizar las diferentes métricas a través del menú desplegable `Show` y puede pasar el ratón por encima de los gráficos de barras para mostrar el valor exacto medido. \n","\n","Le animamos a que pruebe las distintas opciones que vea y también a que modifique el comando. He aquí algunos ejemplos:\n","\n","* Quitando el argumento `slicing_column` obtendrá el corte global.\n","* También puede pasar `race` (ya que se especificó en la configuración de evaluación) para ver los resultados de ese corte en particular.\n","* Usando el deslizador `Examples (Weighted) Threshold` por encima de 5421 eliminará el corte `Female` porque tiene menos ejemplos que ese.\n","* Cambiando el desplegable \"Ver\" a \"Histograma de métricas\" mostrará los resultados divididos en cubos. Por ejemplo, si su columna de corte es \"sexo\" y el desplegable \"Tipo de histograma\" está en \"Recuentos de cortes\", entonces tendrá un corte en dos de los 10 cubos (por defecto), ya que sólo tenemos dos valores para esa característica (\"Masculino\" y \"Femenino\"). El eje x muestra los valores de la métrica en el desplegable \"Seleccionar métrica\". Esta es la vista por defecto cuando el número de cortes es grande.\n","* En la parte inferior de la pantalla, observará que las medidas también se presentan en formato tabular. Puede ordenarlas haciendo clic en los encabezados de los nombres de las características."]},{"cell_type":"code","metadata":{"id":"hJ5_UMnWYmaE"},"source":["# Render metrics for a feature\n","tfma.view.render_slicing_metrics(eval_result, slicing_column='sex')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hSnqI6Esb1XM"},"source":["### Más cortes\n","\n","Si aún no lo has hecho, también puedes pasar el valor `native-country` a la columna de segmentación. La diferencia en esta visualización es que antes sólo especificamos dos de sus valores en la configuración de evaluación. Esto es útil si sólo desea estudiar un subgrupo de una característica en particular y no todo el dominio."]},{"cell_type":"code","metadata":{"id":"355wqvY3yBod"},"source":["# Render metrics for feature. Review EvalConfig message to see what values were selected.\n","tfma.view.render_slicing_metrics(eval_result, slicing_column='native-country')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PsXM0NYGeajg"},"source":["TFMA también permite crear cruces de características para analizar combinaciones de características. Nuestra configuración original creó un cruce entre `sex` y `race` y puede pasarlo como [SlicingSpec](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/SlicingSpec) como se muestra a continuación."]},{"cell_type":"code","metadata":{"id":"k7vbFS1Me1SH"},"source":["# Render metrics for feature crosses\n","tfma.view.render_slicing_metrics(\n","    eval_result,\n","    slicing_spec=tfma.SlicingSpec(\n","        feature_keys=['sex', 'race']))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GmeODqrUfJw2"},"source":["En algunos casos, al cruzar las dos columnas se crean muchas combinaciones. Puede acotar los resultados para fijarse sólo en valores específicos especificándolo en el argumento `slicing_spec`. A continuación se muestran los resultados de la característica `sex` para la raza `Other`."]},{"cell_type":"code","metadata":{"id":"kdvBNfcHfRWg"},"source":["# Narrow down the feature crosses by specifying feature values\n","tfma.view.render_slicing_metrics(\n","    eval_result,\n","    slicing_spec=tfma.SlicingSpec(\n","        feature_keys=['sex'], feature_values={'race': 'Other'}))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f8acksU33KMm"},"source":["### Representación de gráficos\n","\n","Cualquier gráfico que se haya añadido a `tfma.EvalConfig` como `metric_specs` posterior al entrenamiento puede visualizarse utilizando [`tfma.view.render_plot`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/view/render_plot).\n","\n","Al igual que con las métricas, los gráficos pueden visualizarse por cortes. A diferencia de las métricas, sólo pueden mostrarse los gráficos de un valor de corte concreto, por lo que debe utilizarse `tfma.SlicingSpec`, que debe especificar tanto el nombre como el valor de la característica de corte. Si no se especifica ninguna porción, se utilizarán los gráficos de la porción `Overall`.\n","\n","El siguiente ejemplo muestra los gráficos calculados para el corte `sex:Male`. Puede hacer clic en los nombres de la parte inferior del gráfico para ver un tipo de gráfico diferente. Alternativamente, puede marcar la casilla `Mostrar todos los gráficos` para mostrar todos los gráficos en una pantalla."]},{"cell_type":"code","metadata":{"id":"X4TCKjGw3S-a"},"source":["# Render plots\n","tfma.view.render_plot(\n","    eval_result,\n","    tfma.SlicingSpec(feature_values={'sex': 'Male'}))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"meRvFkKcPbux"},"source":["## Seguimiento del rendimiento del modelo a lo largo del tiempo\n","\n","Su conjunto de datos de entrenamiento se utilizará para entrenar su modelo, y es de esperar que sea representativo de su conjunto de datos de prueba y de los datos que se enviarán a su modelo en producción.  Sin embargo, aunque los datos en las solicitudes de inferencia pueden seguir siendo los mismos que sus datos de entrenamiento, también pueden empezar a cambiar lo suficiente como para que cambie el rendimiento de su modelo. Esto significa que necesita supervisar y medir el rendimiento de su modelo de forma continua para que pueda ser consciente de los cambios y reaccionar ante ellos.\n","\n","Veamos cómo puede ayudarle TFMA. Cargará tres conjuntos de datos diferentes y comparará los resultados del análisis del modelo utilizando el método [`render_time_series()`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/view/render_time_series)."]},{"cell_type":"code","metadata":{"id":"zJYUOjmFfuPy"},"source":["import os\n","\n","# Put data paths we prepared earlier in a list\n","TFRECORDS = [TFRECORD_DAY1, TFRECORD_DAY2, TFRECORD_DAY3]\n","\n","# Initialize output paths list for each result \n","output_paths = []\n","\n","# Run eval on each tfrecord separately\n","for num, tfrecord in enumerate(TFRECORDS):\n","\n","  # Use the same model as before\n","  eval_shared_model = tfma.default_eval_shared_model(\n","      eval_saved_model_path=MODEL1_FILE,\n","      eval_config=eval_config)\n","\n","  # Prepare output path name\n","  output_path = os.path.join('.', 'time_series', str(num))\n","  output_paths.append(output_path)\n","\n","  # Run TFMA on the current tfrecord in the loop\n","  tfma.run_model_analysis(eval_shared_model=eval_shared_model,\n","                          eval_config=eval_config,\n","                          data_location=tfrecord,\n","                          output_path=output_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RsO-gqCRK0ar"},"source":["En primer lugar, imagina que has entrenado y desplegado tu modelo ayer. Y ahora quiere ver cómo funciona con los nuevos datos que llegan hoy.  La visualización comenzará mostrando el AUC. Desde la interfaz de usuario, puede:\n","\n","* Añadir otras métricas utilizando el menú \"Añadir serie de métricas\".\n","* Cerrar los gráficos no deseados haciendo clic en x\n","* Pasar el ratón por encima de los puntos de datos (los extremos de los segmentos de línea en el gráfico) para obtener más detalles.\n","\n","Nota: En los gráficos de series métricas, el eje x es simplemente el nombre del directorio del modelo que estás examinando."]},{"cell_type":"code","metadata":{"id":"KjEws8T0cDm9"},"source":["# Load results for day 1 and day 2 datasets\n","eval_results_from_disk = tfma.load_eval_results(output_paths[:2])\n","\n","# Visualize results\n","tfma.view.render_time_series(eval_results_from_disk)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EQ7kZxESN9Bx"},"source":["Ahora imagina que ha pasado otro día y quieres ver cómo le va con los nuevos datos que llegan hoy."]},{"cell_type":"code","metadata":{"id":"VjQmlXMmLwHf"},"source":["# Load results for all three days\n","eval_results_from_disk = tfma.load_eval_results(output_paths)\n","\n","# Visualize the results\n","tfma.view.render_time_series(eval_results_from_disk)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oWD68u-emPN9"},"source":["Este tipo de investigación le permite ver si su modelo se comporta mal con los nuevos datos. A partir de estos resultados, puede tomar la decisión de reentrenar su modelo de producción. Es posible que el reentrenamiento no siempre produzca los mejores resultados, por lo que también necesita una forma de detectarlo. Verá cómo TFMA le ayuda en este sentido en la siguiente sección."]},{"cell_type":"markdown","metadata":{"id":"N1jpShgQxlVL"},"source":["## Validación de modelos\n","\n","TFMA puede configurarse para evaluar varios modelos al mismo tiempo. Típicamente, esto se hace para comparar un modelo candidato contra una línea de base (como el modelo actualmente en servicio) para determinar cuáles son las diferencias de rendimiento en las métricas. Cuando se configuran [umbrales](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/MetricThreshold), TFMA producirá un registro [`tfma.ValidationResult`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/ValidationResult) indicando si el rendimiento coincide con las expectativas.\n","\n","A continuación, reconfigurará los ajustes de EvalConfig para comparar dos modelos: un candidato y una línea de base. También validará el rendimiento del candidato frente a la línea de base estableciendo un [`tmfa.MetricThreshold`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/MetricThreshold) en la métrica `BinaryAccuracy`. Esto ayuda a determinar si el nuevo modelo puede reemplazar al modelo actual."]},{"cell_type":"code","metadata":{"id":"kkatdR6Y1-4G"},"source":["# Setup tfma.EvalConfig setting with metric thresholds\n","eval_config_with_thresholds = text_format.Parse(\"\"\"\n","  ## Model information\n","  model_specs {\n","    name: \"candidate\"\n","    label_key: \"label\"\n","  }\n","  model_specs {\n","    name: \"baseline\"\n","    label_key: \"label\"\n","    is_baseline: true\n","  }\n","\n","  ## Post training metric information\n","  metrics_specs {\n","    metrics { class_name: \"ExampleCount\" }\n","    metrics {\n","      class_name: \"BinaryAccuracy\"\n","      threshold {\n","        # Ensure that metric is always > 0.9\n","        value_threshold {\n","          lower_bound { value: 0.9 }\n","        }\n","        # Ensure that metric does not drop by more than a small epsilon\n","        # e.g. (candidate - baseline) > -1e-10 or candidate > baseline - 1e-10\n","        change_threshold {\n","          direction: HIGHER_IS_BETTER\n","          absolute { value: -1e-10 }\n","        }\n","      }\n","    }\n","    metrics { class_name: \"BinaryCrossentropy\" }\n","    metrics { class_name: \"AUC\" }\n","    metrics { class_name: \"AUCPrecisionRecall\" }\n","    metrics { class_name: \"Precision\" }\n","    metrics { class_name: \"Recall\" }\n","    metrics { class_name: \"MeanLabel\" }\n","    metrics { class_name: \"MeanPrediction\" }\n","    metrics { class_name: \"Calibration\" }\n","    metrics { class_name: \"CalibrationPlot\" }\n","    metrics { class_name: \"ConfusionMatrixPlot\" }\n","    # ... add additional metrics and plots ...\n","  }\n","\n","  ## Slicing information\n","  slicing_specs {}  # overall slice\n","  slicing_specs {\n","    feature_keys: [\"race\"]\n","  }\n","  slicing_specs {\n","    feature_keys: [\"sex\"]\n","  }\n","\"\"\", tfma.EvalConfig())\n","\n","# Create tfma.EvalSharedModels that points to the candidate and baseline\n","candidate_model_path = MODEL1_FILE\n","baseline_model_path = MODEL2_FILE\n","\n","eval_shared_models = [\n","  tfma.default_eval_shared_model(\n","      model_name=tfma.CANDIDATE_KEY,\n","      eval_saved_model_path=candidate_model_path,\n","      eval_config=eval_config_with_thresholds),\n","  tfma.default_eval_shared_model(\n","      model_name=tfma.BASELINE_KEY,\n","      eval_saved_model_path=baseline_model_path,\n","      eval_config=eval_config_with_thresholds),\n","]\n","\n","# Specify validation path\n","validation_output_path = os.path.join(OUTPUT_DIR, 'validation')\n","\n","# Run TFMA on the two models\n","eval_result_with_validation = tfma.run_model_analysis(\n","    eval_shared_models,\n","    eval_config=eval_config_with_thresholds,\n","    data_location=TFRECORD_FULL,\n","    output_path=validation_output_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"siF6npd3IfJq"},"source":["Cuando se ejecutan evaluaciones con uno o más modelos frente a una línea de base, TFMA añade automáticamente métricas diferentes para todas las métricas calculadas durante la evaluación. Estas métricas reciben el mismo nombre que la métrica correspondiente, pero con la cadena `_diff` añadida al nombre de la métrica. Un valor positivo de estas métricas `_diff` indica una mejora del rendimiento con respecto a la línea de base.\n","\n","Al igual que en la sección anterior, puede ver los resultados con `render_time_series()`."]},{"cell_type":"code","metadata":{"id":"yGIw9TDuJ7wn"},"source":["# Render results\n","tfma.view.render_time_series(eval_result_with_validation)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JIsehm_V4oKU"},"source":["Puede utilizar [`tfma.load_validator_result`](https://www.tensorflow.org/tfx/model_analysis/api_docs/python/tfma/load_validation_result) para ver los resultados de la validación que especificó con la configuración del umbral. En este ejemplo, la validación falla porque `BinaryAccuracy` está por debajo del umbral."]},{"cell_type":"code","metadata":{"id":"48EdSTUW5eE1"},"source":["# Print validation result\n","validation_result = tfma.load_validation_result(validation_output_path)\n","print(validation_result.validation_ok)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aBhzlF-lqRFY"},"source":["**¡Enhorabuena! Ya ha explorado los diferentes métodos de análisis de modelos utilizando TFMA. En la siguiente sección, verá cómo estos pueden encajar en una canalización TFX para que pueda automatizar el proceso y almacenar los resultados en su directorio de canalización y almacén de metadatos.**"]},{"cell_type":"code","source":[],"metadata":{"id":"wAvAJPCK5YpR"},"execution_count":null,"outputs":[]}]}