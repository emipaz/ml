{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4vEEajUbvNc"
      },
      "source": [
        "# Laboratorio no calificado: Ajuste de hiperparámetros y entrenamiento de modelos con TFX\n",
        "\n",
        "En este laboratorio, volverá a realizar el ajuste de hiperparámetros, pero esta vez, será dentro de un pipeline [Tensorflow Extended (TFX)](https://www.tensorflow.org/tfx/). \n",
        "\n",
        "Ya hemos introducido algunos componentes de TFX en el Curso 2 de esta especialización relacionados con la ingestión, validación y transformación de datos. En este cuaderno, llegarás a trabajar con dos más que están relacionados con el desarrollo y entrenamiento de modelos: *Tuner* y *Trainer*.\n",
        "\n",
        "<img src='https://www.tensorflow.org/tfx/guide/images/prog_trainer.png' alt='tfx pipeline'>\n",
        "image source: https://www.tensorflow.org/tfx/guide\n",
        "\n",
        "* El *Tuner* utiliza la API [Keras Tuner](https://keras-team.github.io/keras-tuner/) para ajustar los hiperparámetros de su modelo.\n",
        "* Puedes obtener el mejor conjunto de hiperparámetros del componente Tuner y alimentar el componente *Trainer* para optimizar tu modelo para el entrenamiento.\n",
        "\n",
        "Volverá a trabajar con el conjunto de datos [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) y lo alimentará a través de la tubería TFX hasta el componente Trainer.Repasará rápidamente los componentes anteriores del Curso 2, y luego se centrará en los dos nuevos componentes introducidos.\n",
        "\n",
        "Comencemos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEFWSi_-umNz"
      },
      "source": [
        "### Instalar TFX\n",
        "\n",
        "Primero instalará [TFX](https://www.tensorflow.org/tfx), un marco de trabajo para el desarrollo de pipelines de aprendizaje automático de extremo a extremo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "source": [
        "!pip install --use-deprecated=legacy-resolver tfx==1.3.0\n",
        "!pip install apache-beam==2.32.0\n",
        "\n",
        "# These are downgraded to work with the packages used by TFX 1.3\n",
        "# Please do not delete because it will cause import errors in the next cell\n",
        "!pip install tensorflow==2.6.0\n",
        "!pip install tensorflow-serving-api==2.6.0\n",
        "!pip install --upgrade tensorflow-estimator==2.6.0\n",
        "!pip install --upgrade keras==2.6.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr2ulfeNvvom"
      },
      "source": [
        "*Nota: En Google Colab, es necesario reiniciar el tiempo de ejecución en este punto para finalizar la actualización de los paquetes que acaba de instalar. Puede hacerlo haciendo clic en el botón \"Reiniciar el tiempo de ejecución\" al final de la celda de salida anterior (después de la instalación), o seleccionando \"Tiempo de ejecución > Reiniciar el tiempo de ejecución\" en la barra de menús. **Por favor, no pases a la siguiente sección sin reiniciar.** También puedes ignorar los errores de incompatibilidad de versiones de algunos de los paquetes incluidos porque no los usaremos en este cuaderno.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_MPhjWTvNSr"
      },
      "source": [
        "### Imports\n",
        "\n",
        "A continuación, importará los paquetes que necesitará para este ejercicio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_leAIdFKAxAD"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "import pprint\n",
        "\n",
        "from tfx.components import ImportExampleGen\n",
        "from tfx.components import ExampleValidator\n",
        "from tfx.components import SchemaGen\n",
        "from tfx.components import StatisticsGen\n",
        "from tfx.components import Transform\n",
        "from tfx.components import Tuner\n",
        "from tfx.components import Trainer\n",
        "\n",
        "from tfx.proto import example_gen_pb2\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReV_UXOgCZvx"
      },
      "source": [
        "## Descargar y preparar el conjunto de datos\n",
        "\n",
        "Como se mencionó anteriormente, se utilizará el conjunto de datos Fashion MNIST al igual que en el laboratorio anterior. Esto le permitirá comparar las similitudes y diferencias al utilizar Keras Tuner como una biblioteca independiente y dentro de una tubería ML.\n",
        "\n",
        "En primer lugar, tendrá que configurar los directorios que utilizará para almacenar el conjunto de datos, así como los artefactos de la tubería y el almacén de metadatos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNQlwf5_t8Fc"
      },
      "source": [
        "# Location of the pipeline metadata store\n",
        "_pipeline_root = './pipeline/'\n",
        "\n",
        "# Directory of the raw data files\n",
        "_data_root = './data/fmnist'\n",
        "\n",
        "# Temporary directory\n",
        "tempdir = './tempdir'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqwtVwAsslgN"
      },
      "source": [
        "# Create the dataset directory\n",
        "!mkdir -p {_data_root}\n",
        "\n",
        "# Create the TFX pipeline files directory\n",
        "!mkdir {_pipeline_root}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyjfgG0ax9uv"
      },
      "source": [
        "Ahora descargará FashionMNIST desde [Tensorflow Datasets](https://www.tensorflow.org/datasets). La bandera `with_info` se establecerá en `True` para que pueda mostrar información sobre el conjunto de datos en la siguiente celda (es decir, utilizando `ds_info`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUzvq3WFvKyl"
      },
      "source": [
        "# Download the dataset\n",
        "ds, ds_info = tfds.load('fashion_mnist', data_dir=tempdir, with_info=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74BnhUcG1A-x"
      },
      "source": [
        "# Display info about the dataset\n",
        "print(ds_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuByMtNV13JH"
      },
      "source": [
        "Puedes revisar los archivos descargados con el código de abajo. Para este laboratorio, utilizará el TFRecord *train* por lo que deberá tomar nota de su nombre de archivo. En este laboratorio no utilizarás el TFRecord *test*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A501bxQd1Qxo"
      },
      "source": [
        "# Define the location of the train tfrecord downloaded via TFDS\n",
        "tfds_data_path = f'{tempdir}/{ds_info.name}/{ds_info.version}'\n",
        "\n",
        "# Display contents of the TFDS data directory\n",
        "os.listdir(tfds_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obla1v0RzXdB"
      },
      "source": [
        "A continuación, copiará la división del tren de los datos descargados para que pueda ser consumida por el componente ExampleGen en el siguiente paso. Este componente requiere que sus archivos estén en un directorio sin archivos adicionales (por ejemplo, archivos JSON y TXT)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49ZklvN8d64e"
      },
      "source": [
        "# Define the train tfrecord filename\n",
        "train_filename = 'fashion_mnist-train.tfrecord-00000-of-00001'\n",
        "\n",
        "# Copy the train tfrecord into the data root folder\n",
        "!cp {tfds_data_path}/{train_filename} {_data_root}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo {tfds_data_path}/{train_filename} {_data_root}"
      ],
      "metadata": {
        "id": "ysBjWYSEKzkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUy9vZq72ueR"
      },
      "source": [
        "## Tubería TFX\n",
        "\n",
        "Una vez completada la configuración, puede proceder a crear la tubería. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1gu2Bbi226z"
      },
      "source": [
        "### Inicializar el Contexto Interactivo\n",
        "\n",
        "Comenzará inicializando el [Contexto Interactivo](https://github.com/tensorflow/tfx/blob/master/tfx/orchestration/experimental/interactive/interactive_context.py) para poder ejecutar los componentes dentro de este entorno Colab. Puede ignorar la advertencia porque sólo utilizará un archivo local SQLite para el almacenamiento de metadatos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeCZ5mAvvlD4"
      },
      "source": [
        "# Initialize the InteractiveContext\n",
        "context = InteractiveContext(pipeline_root=_pipeline_root)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQwR6Cex3azZ"
      },
      "source": [
        "### ExampleGen\n",
        "\n",
        "Comenzará el pipeline ingiriendo el TFRecord que haya apartado. El [ImportExampleGen](https://www.tensorflow.org/tfx/api_docs/python/tfx/components/ImportExampleGen) consume TFRecords y puede especificar divisiones como se muestra a continuación. Para este ejercicio, usted dividirá el tfrecord de entrenamiento para usar el 80% para el conjunto de entrenamiento, y el 20% restante como conjunto de evaluación/validación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xolw1d8lvqNW"
      },
      "source": [
        "# Specify 80/20 split for the train and eval set\n",
        "output = example_gen_pb2.Output(\n",
        "    split_config = example_gen_pb2.SplitConfig(splits=[\n",
        "        example_gen_pb2.SplitConfig.Split(name = 'train', hash_buckets = 8),\n",
        "        example_gen_pb2.SplitConfig.Split(name = 'eval',  hash_buckets = 2),\n",
        "    ]))\n",
        "\n",
        "# Ingest the data through ExampleGen\n",
        "example_gen = ImportExampleGen(input_base = _data_root, output_config = output)\n",
        "\n",
        "# Run the component\n",
        "context.run(example_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIdWfRWGxvHp"
      },
      "source": [
        "# Print split names and URI\n",
        "artifact = example_gen.outputs['examples'].get()[0]\n",
        "print(artifact.split_names, artifact.uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os6NhLaY4oB3"
      },
      "source": [
        "### StatisticsGen\n",
        "\n",
        "A continuación, calculará las estadísticas del conjunto de datos con el componente [StatisticsGen](https://www.tensorflow.org/tfx/guide/statsgen)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVDS4oEIzZ83"
      },
      "source": [
        "# Run StatisticsGen\n",
        "statistics_gen = StatisticsGen(\n",
        "    examples=example_gen.outputs['examples'])\n",
        "\n",
        "context.run(statistics_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D48bfGK95sES"
      },
      "source": [
        "### SchemaGen\n",
        "\n",
        "A continuación, puede inferir el esquema del conjunto de datos con [SchemaGen](https://www.tensorflow.org/tfx/guide/schemagen). Esto se utilizará para validar los datos entrantes para asegurar que están formateados correctamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UhV3Jr7zp7p"
      },
      "source": [
        "# Run SchemaGen\n",
        "schema_gen = SchemaGen(\n",
        "      statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
        "context.run(schema_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtS2ZEgCzvAf"
      },
      "source": [
        "# Visualize the results\n",
        "context.show(schema_gen.outputs['schema'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_yXqq1y6LR6"
      },
      "source": [
        "### ExampleValidator\n",
        "\n",
        "Se puede suponer que el conjunto de datos está limpio ya que lo hemos descargado de TFDS. Pero sólo para revisar, vamos a ejecutarlo a través de [ExampleValidator](https://www.tensorflow.org/tfx/guide/exampleval) para detectar si hay anomalías dentro del conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaTJiYPpzzZM"
      },
      "source": [
        "# Run ExampleValidator\n",
        "example_validator = ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=schema_gen.outputs['schema'])\n",
        "context.run(example_validator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6YzedBSz5KE"
      },
      "source": [
        "# Visualize the results. There should be no anomalies.\n",
        "context.show(example_validator.outputs['anomalies'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpUFIO9M6yMH"
      },
      "source": [
        "### Transform\n",
        "\n",
        "Utilicemos ahora el componente [Transform](https://www.tensorflow.org/tfx/guide/transform) para escalar los píxeles de la imagen y convertir los tipos de datos a float. Primero definiremos el módulo de transformación que contiene estas operaciones antes de ejecutar el componente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL4zrcJ7z9K9"
      },
      "source": [
        "_transform_module_file = 'fmnist_transform.py'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43xmp2UD0Cc5"
      },
      "source": [
        "%%writefile {_transform_module_file}\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "# Keys\n",
        "_LABEL_KEY = 'label'\n",
        "_IMAGE_KEY = 'image'\n",
        "\n",
        "\n",
        "def _transformed_name(key):\n",
        "    return key + '_xf'\n",
        "\n",
        "def _image_parser(image_str):\n",
        "    '''converts the images to a float tensor'''\n",
        "    image = tf.image.decode_image(image_str, channels=1)\n",
        "    image = tf.reshape(image, (28, 28, 1))\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    return image\n",
        "\n",
        "\n",
        "def _label_parser(label_id):\n",
        "    '''converts the labels to a float tensor'''\n",
        "    label = tf.cast(label_id, tf.float32)\n",
        "    return label\n",
        "\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "    \"\"\"Función de retorno de tf.transform para el preprocesamiento de entradas.\n",
        "    Args:\n",
        "        inputs: mapa de claves de características a características crudas aún no transformadas.\n",
        "    Devuelve:\n",
        "        Mapa de claves de características de cadena a operaciones de características transformadas.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Convert the raw image and labels to a float array\n",
        "    with tf.device(\"/cpu:0\"):\n",
        "        outputs = {\n",
        "            _transformed_name(_IMAGE_KEY):\n",
        "                tf.map_fn(\n",
        "                    _image_parser,\n",
        "                    tf.squeeze(inputs[_IMAGE_KEY], axis=1),\n",
        "                    dtype=tf.float32),\n",
        "            _transformed_name(_LABEL_KEY):\n",
        "                tf.map_fn(\n",
        "                    _label_parser,\n",
        "                    inputs[_LABEL_KEY],\n",
        "                    dtype=tf.float32)\n",
        "        }\n",
        "    \n",
        "    # scale the pixels from 0 to 1\n",
        "    outputs[_transformed_name(_IMAGE_KEY)] = tft.scale_to_0_1(outputs[_transformed_name(_IMAGE_KEY)])\n",
        "    \n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uNYsebhLC69"
      },
      "source": [
        "You will run the component by passing in the examples, schema, and transform module file.\n",
        "\n",
        "*Note: You can safely ignore the warnings and `udf_utils` related errors.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qthHA2hO1JST"
      },
      "source": [
        "# Ignore TF warning messages\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# Setup the Transform component\n",
        "transform = Transform(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    module_file=os.path.abspath(_transform_module_file))\n",
        "\n",
        "# Run the component\n",
        "context.run(transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZkbL7sO8Y1N"
      },
      "source": [
        "### Tuner\n",
        "\n",
        "Como su nombre indica, el componente [Tuner](https://www.tensorflow.org/tfx/guide/tuner) ajusta los hiperparámetros de su modelo. Para utilizarlo, tendrá que proporcionar un *archivo de módulo tuner* que contenga una función `tuner_fn()`. En esta función, usted hará en su mayoría los mismos pasos que hizo en el laboratorio anterior no calificado, pero con algunas diferencias clave en el manejo del conjunto de datos. \n",
        "\n",
        "El componente Transform guardó anteriormente los ejemplos transformados como TFRecords comprimidos en formato `.gz` y necesitará cargarlo en la memoria. Una vez cargado, necesitará crear lotes de características y etiquetas para que finalmente pueda utilizarlo para la hibridación. Este proceso está modularizado en el `_input_fn()` de abajo. \n",
        "\n",
        "Volviendo, la función `tuner_fn()` devolverá un `TunerFnResult` [namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple) que contiene su objeto `tuner` y un conjunto de argumentos para pasar al método `tuner.search()`. Verás esto en acción en las siguientes celdas. Cuando revises el archivo del módulo, te recomendamos que veas primero la función `tuner_fn()` antes de ver las otras funciones auxiliares."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE1PLAs_6CVt"
      },
      "source": [
        "# Declare name of module file\n",
        "_tuner_module_file = 'tuner.py'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0F-XhqVlUDB"
      },
      "source": [
        "%%writefile {_tuner_module_file}\n",
        "\n",
        "# Define imports\n",
        "from kerastuner.engine import base_tuner\n",
        "import kerastuner as kt\n",
        "from tensorflow import keras\n",
        "from typing import NamedTuple, Dict, Text, Any, List\n",
        "from tfx.components.trainer.fn_args_utils import FnArgs, DataAccessor\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "# Declare namedtuple field names\n",
        "TunerFnResult = NamedTuple('TunerFnResult', [('tuner', base_tuner.BaseTuner),\n",
        "                                             ('fit_kwargs', Dict[Text, Any])])\n",
        "\n",
        "# Label key\n",
        "LABEL_KEY = 'label_xf'\n",
        "\n",
        "# Callback for the search strategy\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "\n",
        "def _gzip_reader_fn(filenames):\n",
        "  '''Lconjunto de datos comprimidos oad\n",
        "  \n",
        "  Args:\n",
        "    filenames - nombres de archivos de TFRecords a cargar\n",
        "\n",
        "  Devuelve:\n",
        "    TFRecordDataset cargado a partir de los nombres de archivo\n",
        "  '''\n",
        "\n",
        "  # Cargar el conjunto de datos. Especifica el tipo de compresión ya que se guarda como `.gz`.\n",
        "  return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
        "  \n",
        "\n",
        "def _input_fn(file_pattern,\n",
        "              tf_transform_output,\n",
        "              num_epochs=None,\n",
        "              batch_size=32) -> tf.data.Dataset:\n",
        "  '''Crear lotes de características y etiquetas a partir de registros TF\n",
        "\n",
        "  Args:\n",
        "    file_pattern - Lista de archivos o patrones de rutas de archivos que contienen registros de ejemplo.\n",
        "    tf_transform_output - Gráfico de salida de la transformación\n",
        "    num_epochs - Número entero que especifica el número de veces que hay que leer el conjunto de datos. \n",
        "            Si es None, se recorre el conjunto de datos para siempre.\n",
        "    batch_size - Un int que representa el número de registros a combinar en un solo lote.\n",
        "\n",
        "  Devuelve:\n",
        "    Un conjunto de datos de elementos dict, (o una tupla de elementos dict y etiqueta). \n",
        "    Cada dict asigna claves de características a objetos Tensor o SparseTensor.\n",
        "  '''\n",
        "\n",
        "  # Get feature specification based on transform output\n",
        "  transformed_feature_spec = (\n",
        "      tf_transform_output.transformed_feature_spec().copy())\n",
        "  \n",
        "  # Create batches of features and labels\n",
        "  dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "      file_pattern=file_pattern,\n",
        "      batch_size=batch_size,\n",
        "      features=transformed_feature_spec,\n",
        "      reader=_gzip_reader_fn,\n",
        "      num_epochs=num_epochs,\n",
        "      label_key=LABEL_KEY)\n",
        "  \n",
        "  return dataset\n",
        "\n",
        "\n",
        "def model_builder(hp):\n",
        "  '''\n",
        "  Construye el modelo y establece los hiperparámetros a afinar.\n",
        "\n",
        "  Args:\n",
        "    hp - Objeto Keras tuner\n",
        "\n",
        "  Devuelve:\n",
        "    Modelo con los hiperparámetros a sintonizar\n",
        "  '''\n",
        "\n",
        "  # Inicializar la API secuencial y empezar a apilar las capas\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28, 1)))\n",
        "\n",
        "  # Ajuste el número de unidades en la primera capa densa\n",
        "  # Elija un valor óptimo entre 32-512\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu', name='dense_1'))\n",
        "\n",
        "  # Add next layers\n",
        "  model.add(keras.layers.Dropout(0.2))\n",
        "  model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  # Ajuste la tasa de aprendizaje para el optimizador\n",
        "  # Elija un valor óptimo entre 0,01, 0,001 o 0,0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "def tuner_fn(fn_args: FnArgs) -> TunerFnResult:\n",
        "  \"\"\"Construye el sintonizador utilizando la API KerasTuner.\n",
        "  Argumentos:\n",
        "    fn_args: contiene los argumentos como pares nombre/valor.\n",
        "\n",
        "      - working_dir: directorio de trabajo para el ajuste.\n",
        "      - train_files: Lista de rutas de archivos que contienen datos de entrenamiento tf.Example.\n",
        "      - eval_files: Lista de rutas de archivos que contienen datos de tf.Example de evaluación.\n",
        "      - train_steps: número de pasos de entrenamiento.\n",
        "      - eval_steps: número de pasos de evaluación.\n",
        "      - schema_path: esquema opcional de los datos de entrada.\n",
        "      - transform_graph_path: gráfico de transformación opcional producido por TFT.\n",
        "  \n",
        "  Devuelve:\n",
        "    Una namedtuple que contiene lo siguiente:\n",
        "      - tuner: un BaseTuner que se utilizará para el ajuste.\n",
        "      - fit_kwargs: Args para pasar a la función run_trial del sintonizador para ajustar el\n",
        "                    modelo, por ejemplo, el conjunto de datos de entrenamiento y validación. Se requiere\n",
        "                    depende de la implementación del sintonizador anterior.\n",
        "  \"\"\"\n",
        "\n",
        "  # Define tuner search strategy\n",
        "  tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory=fn_args.working_dir,\n",
        "                     project_name='kt_hyperband')\n",
        "\n",
        "  # Load transform output\n",
        "  tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
        "\n",
        "  # Use _input_fn() to extract input features and labels from the train and val set\n",
        "  train_set = _input_fn(fn_args.train_files[0], tf_transform_output)\n",
        "  val_set = _input_fn(fn_args.eval_files[0], tf_transform_output)\n",
        "\n",
        "\n",
        "  return TunerFnResult(\n",
        "      tuner=tuner,\n",
        "      fit_kwargs={ \n",
        "          \"callbacks\":[stop_early],\n",
        "          'x': train_set,\n",
        "          'validation_data': val_set,\n",
        "          'steps_per_epoch': fn_args.train_steps,\n",
        "          'validation_steps': fn_args.eval_steps\n",
        "      }\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzJbeuXNtI-7"
      },
      "source": [
        "Con el módulo definido, ahora puede configurar el componente Tuner. Puedes ver la descripción de cada argumento [aquí](https://www.tensorflow.org/tfx/api_docs/python/tfx/components/Tuner). \n",
        "\n",
        "Fíjate que pasamos un argumento `num_steps` a los argumentos train y eval y esto fue usado en los argumentos `steps_per_epoch` y `validation_steps` en el módulo tuner de arriba. Esto puede ser útil si no se quiere recorrer todo el conjunto de datos al afinar. Por ejemplo, si tienes 10GB de datos de entrenamiento, sería increíblemente lento si lo recorres por completo sólo para una época y un conjunto de hiperparámetros. Puede establecer el número de pasos para que su programa sólo pase por una fracción del conjunto de datos. \n",
        "\n",
        "Usted puede calcular el número total de pasos en una época por: `número de ejemplos / tamaño del lote`. Para este ejemplo en particular, tenemos `48000 ejemplos / 32 (tamaño por defecto)` lo que equivale a `1500` pasos por época para el conjunto de entrenamiento (calcular los pasos val de 12000 ejemplos). Dado que has pasado `500` en el `num_steps` de los argumentos del tren, esto significa que algunos ejemplos se saltarán. Esto probablemente resultará en lecturas de menor precisión pero ahorrará tiempo al hacer el hipertuning. Intente modificar este valor más tarde y vea si llega al mismo conjunto de hiperparámetros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqVSc6sS5A1m"
      },
      "source": [
        "from tfx.proto import trainer_pb2\n",
        "\n",
        "# Setup the Tuner component\n",
        "tuner = Tuner(\n",
        "    module_file=_tuner_module_file,\n",
        "    examples=transform.outputs['transformed_examples'],\n",
        "    transform_graph=transform.outputs['transform_graph'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    train_args=trainer_pb2.TrainArgs(splits=['train'], num_steps=500),\n",
        "    eval_args=trainer_pb2.EvalArgs(splits=['eval'], num_steps=100)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdycQnAR7AvG"
      },
      "source": [
        "# Run the component. This will take around 10 minutes to run.\n",
        "# When done, it will summarize the results and show the 10 best trials.\n",
        "context.run(tuner, enable_cache=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW50JS0d9Hd4"
      },
      "source": [
        "### Trainer\n",
        "\n",
        "Al igual que el componente Tuner, el componente [Trainer](https://www.tensorflow.org/tfx/guide/trainer) también requiere un archivo de módulo para configurar el proceso de entrenamiento. Buscará una función `run_fn()` que defina y entrene el modelo. Los pasos serán similares a los del archivo de módulo del sintonizador:\n",
        "\n",
        "* Definir el modelo - Puedes obtener los resultados del componente Tuner a través del argumento `fn_args.hyperparameters`. Lo verás pasado a la función `model_builder()` más abajo. Si no has ejecutado `Tuner`, entonces puedes definir explícitamente el número de unidades ocultas y la tasa de aprendizaje.\n",
        "\n",
        "* Cargar los conjuntos de entrenamiento y validación - Esto lo has hecho en el componente Tuner. Para este módulo, pasarás un valor `num_epochs` (10) para indicar cuántos lotes serán preparados. Puede optar por no hacer esto y pasar un valor `num_steps` como antes.\n",
        "\n",
        "* Configurar y entrenar el modelo - Esto te resultará muy familiar si ya estás acostumbrado a la [Keras Models Training API](https://keras.io/api/models/model_training_apis/). Puedes pasar callbacks como el [TensorBoard callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) para poder visualizar los resultados más tarde.\n",
        "\n",
        "* Guarda el modelo - Esto es necesario para que puedas analizar y servir tu modelo. Esto lo harás en partes posteriores del curso y de la especialización."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abSJjDM2ipKS"
      },
      "source": [
        "# Declare trainer module file\n",
        "_trainer_module_file = 'trainer.py'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdgbwOFFihSg"
      },
      "source": [
        "%%writefile {_trainer_module_file}\n",
        "\n",
        "from tensorflow import keras\n",
        "from typing import NamedTuple, Dict, Text, Any, List\n",
        "from tfx.components.trainer.fn_args_utils import FnArgs, DataAccessor\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "# Define the label key\n",
        "LABEL_KEY = 'label_xf'\n",
        "\n",
        "def _gzip_reader_fn(filenames):\n",
        "  '''Cargar un conjunto de datos comprimidos\n",
        "  \n",
        "  Args:\n",
        "    filenames - nombres de archivos de TFRecords a cargar\n",
        "\n",
        "  Devuelve:\n",
        "    TFRecordDataset cargado a partir de los nombres de archivo\n",
        "  '''\n",
        "\n",
        "  # Cargar el conjunto de datos. Especifica el tipo de compresión ya que se guarda como `.gz`.\n",
        "  return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
        "  \n",
        "\n",
        "def _input_fn(file_pattern,\n",
        "              tf_transform_output,\n",
        "              num_epochs=None,\n",
        "              batch_size=32) -> tf.data.Dataset:\n",
        "  '''Crear lotes de características y etiquetas a partir de registros TF\n",
        "\n",
        "  Args:\n",
        "    file_pattern - Lista de archivos o patrones de rutas de archivos que contienen registros de ejemplo.\n",
        "    tf_transform_output - Gráfico de salida de la transformación\n",
        "    num_epochs - Número entero que especifica el número de veces que hay que leer el conjunto de datos. \n",
        "            Si es None, se recorre el conjunto de datos para siempre.\n",
        "    batch_size - Un int que representa el número de registros a combinar en un solo lote.\n",
        "\n",
        "  Devuelve:\n",
        "    Un conjunto de datos de elementos dict, (o una tupla de elementos dict y etiqueta). \n",
        "    Cada dict asigna claves de características a objetos Tensor o SparseTensor.\n",
        "  '''\n",
        "  transformed_feature_spec = (\n",
        "      tf_transform_output.transformed_feature_spec().copy())\n",
        "  \n",
        "  dataset = tf.data.experimental.make_batched_features_dataset(\n",
        "      file_pattern=file_pattern,\n",
        "      batch_size=batch_size,\n",
        "      features=transformed_feature_spec,\n",
        "      reader=_gzip_reader_fn,\n",
        "      num_epochs=num_epochs,\n",
        "      label_key=LABEL_KEY)\n",
        "  \n",
        "  return dataset\n",
        "\n",
        "\n",
        "def model_builder(hp):\n",
        "  '''\n",
        "  Construye el modelo y establece los hiperparámetros a afinar.\n",
        "\n",
        "  Args:\n",
        "    hp - objeto Keras tuner\n",
        "\n",
        "  Devuelve:\n",
        "    Modelo con los hiperparámetros a sintonizar\n",
        "  '''\n",
        "\n",
        "  # Inicializar la API secuencial y empezar a apilar las capas\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28, 1)))\n",
        "\n",
        "  # Get the number of units from the Tuner results\n",
        "  hp_units = hp.get('units')\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "\n",
        "  # Add next layers\n",
        "  model.add(keras.layers.Dropout(0.2))\n",
        "  model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  # Get the learning rate from the Tuner results\n",
        "  hp_learning_rate = hp.get('learning_rate')\n",
        "\n",
        "  # Setup model for training\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Print the model summary\n",
        "  model.summary()\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "def run_fn(fn_args: FnArgs) -> None:\n",
        "  \"\"\"Define y entrena el modelo.\n",
        "  Argumentos:\n",
        "    fn_args: Contiene los argumentos como pares nombre/valor. Consulte aquí los atributos completos: \n",
        "    https://www.tensorflow.org/tfx/api_docs/python/tfx/components/trainer/fn_args_utils/FnArgs#attributes\n",
        "  \"\"\"\n",
        "\n",
        "  # Callback for TensorBoard\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=fn_args.model_run_dir, update_freq='batch')\n",
        "  \n",
        "  # Load transform output\n",
        "  tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)\n",
        "  \n",
        "  # Create batches of data good for 10 epochs\n",
        "  train_set = _input_fn(fn_args.train_files[0], tf_transform_output, 10)\n",
        "  val_set = _input_fn(fn_args.eval_files[0], tf_transform_output, 10)\n",
        "\n",
        "  # Load best hyperparameters\n",
        "  hp = fn_args.hyperparameters.get('values')\n",
        "\n",
        "  # Build the model\n",
        "  model = model_builder(hp)\n",
        "\n",
        "  # Train the model\n",
        "  model.fit(\n",
        "      x=train_set,\n",
        "      validation_data=val_set,\n",
        "      callbacks=[tensorboard_callback]\n",
        "      )\n",
        "  \n",
        "  # Save the model\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu3fQwFX6E8Q"
      },
      "source": [
        "Puedes pasar la salida del componente `Tuner` al `Trainer` rellenando el argumento `hyperparameters` con la salida del `Tuner`. Esto se indica con el argumento `tuner.outputs['best_hyperparameters']` más abajo. Puedes ver la definición de los otros argumentos [aquí](https://www.tensorflow.org/tfx/api_docs/python/tfx/components/Trainer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0JOuqSKGsoQ"
      },
      "source": [
        "# Setup the Trainer component\n",
        "trainer = Trainer(\n",
        "    module_file     =_trainer_module_file,\n",
        "    examples        = transform.outputs['transformed_examples'],\n",
        "    hyperparameters = tuner.outputs['best_hyperparameters'],\n",
        "    transform_graph = transform.outputs['transform_graph'],\n",
        "    schema          = schema_gen.outputs['schema'],\n",
        "    train_args      = trainer_pb2.TrainArgs(splits=['train']),\n",
        "    eval_args       = trainer_pb2.EvalArgs(splits=['eval']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQfTLKGf7BFk"
      },
      "source": [
        "Tenga en cuenta que al reentrenar su modelo, no siempre tiene que reajustar sus hiperparámetros. Una vez que tengas un conjunto que creas que tiene un buen rendimiento, puedes simplemente importarlo con el ImporterNode como se muestra en los [docs oficiales](https://www.tensorflow.org/tfx/guide/tuner):\n",
        "\n",
        "```\n",
        "hparams_importer = ImporterNode(\n",
        "    instance_name='import_hparams',\n",
        "    # This can be Tuner's output file or manually edited file. The file contains\n",
        "    # text format of hyperparameters (kerastuner.HyperParameters.get_config())\n",
        "    source_uri='path/to/best_hyperparameters.txt',\n",
        "    artifact_type=HyperParameters)\n",
        "\n",
        "trainer = Trainer(\n",
        "    ...\n",
        "    # An alternative is directly use the tuned hyperparameters in Trainer's user\n",
        "    # module code and set hyperparameters to None here.\n",
        "    hyperparameters = hparams_importer.outputs['result'])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwM2743um1w3"
      },
      "source": [
        "# Run the component\n",
        "context.run(trainer, enable_cache=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiuE7i0A8qEb"
      },
      "source": [
        "Su modelo debería estar ahora guardado en el directorio de su pipeline y puede navegar por él como se muestra a continuación. El archivo se guarda como `saved_model.pb`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQPZBkw_yl2i"
      },
      "source": [
        "# Get artifact uri of trainer model output\n",
        "model_artifact_dir = trainer.outputs['model'].get()[0].uri\n",
        "\n",
        "# List subdirectories artifact uri\n",
        "print(f'contents of model artifact directory:{os.listdir(model_artifact_dir)}')\n",
        "\n",
        "# Define the model directory\n",
        "model_dir = os.path.join(model_artifact_dir, 'Format-Serving')\n",
        "\n",
        "# List contents of model directory\n",
        "print(f'contents of model directory: {os.listdir(model_dir)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu5Bsn0J9ol3"
      },
      "source": [
        "También puedes visualizar los resultados del entrenamiento cargando los registros guardados por el callback del Tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPqoMMXv5NoY"
      },
      "source": [
        "model_run_artifact_dir = trainer.outputs['model_run'].get()[0].uri\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {model_run_artifact_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6H6eCKC9xLp"
      },
      "source": [
        "***¡Felicidades! Ahora ha creado un pipeline de ML que incluye el ajuste de hiperparámetros y el entrenamiento del modelo. Sabrá más sobre los siguientes componentes en futuras lecciones, pero en la siguiente sección, primero aprenderá sobre un marco de trabajo para construir automáticamente tuberías de ML: AutoML. Disfruta del resto del curso.***"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wEHaV56pY4N_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}