{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Ungraded Lab: Intro to Keras Tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "El desarrollo de modelos de aprendizaje automático suele ser un proceso iterativo. Se comienza con un diseño inicial y luego se reconfigura hasta conseguir un modelo que pueda ser entrenado de forma eficiente en términos de tiempo y recursos computacionales. Como ya sabrás, estos ajustes que realizas se denominan _hiperparámetros_. Son las variables que gobiernan el proceso de entrenamiento y la topología de un modelo ML. Éstas permanecen constantes a lo largo del proceso de entrenamiento y tienen un impacto directo en el rendimiento de su programa de ML. \n",
        "\n",
        "El proceso de encontrar el conjunto óptimo de hiperparámetros se denomina *ajuste de hiperparámetros* o *hiperajuste*, y es una parte esencial de un proceso de aprendizaje automático. Sin él, se puede acabar con un modelo que tiene parámetros innecesarios y que tarda demasiado en entrenarse.\n",
        "\n",
        "Los hiperparámetros son de dos tipos:\n",
        "1. *Hiperparámetros del modelo* que influyen en la selección del modelo, como el número y la anchura de las capas ocultas\n",
        "\n",
        "2. 2. *Hiperparámetros del algoritmo* que influyen en la velocidad y la calidad del algoritmo de aprendizaje, como la tasa de aprendizaje en el caso del Descenso Gradiente Estocástico (SGD) y el número de vecinos más cercanos en el caso de un clasificador KNN (k Nearest Neighbors).\n",
        "\n",
        "En el caso de modelos más complejos, el número de hiperparámetros puede aumentar drásticamente y ajustarlos manualmente puede ser todo un reto.\n",
        "\n",
        "En este laboratorio, practicarás el ajuste de hiperparámetros con [Keras Tuner](https://keras-team.github.io/keras-tuner/), un paquete del equipo Keras que automatiza este proceso. Para comparar, primero entrenarás un modelo de referencia con hiperparámetros preseleccionados, y luego volverás a realizar el proceso con hiperparámetros ajustados. Algunos de los ejemplos y discusiones aquí son tomados del [tutorial oficial proporcionado por Tensorflow](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb#scrollTo=sKwLOzKpFGAj) pero hemos expuesto algunas partes clave para mayor claridad.\n",
        "\n",
        "¡Comencemos!\n",
        "\n",
        "**Nota: Los cuadernos de este curso son compartidos con acceso de sólo lectura. Para poder guardar tu trabajo, por favor, selecciona Archivo > Guardar una copia en Drive en el menú de Colab y ejecuta el cuaderno desde ahí. Necesitarás una cuenta de Gmail para guardar una copia.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReV_UXOgCZvx"
      },
      "source": [
        "## Descargar y preparar el conjunto de datos\n",
        "\n",
        "Primero carguemos el [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) en su espacio de trabajo. Lo utilizarás para entrenar un modelo de aprendizaje automático que clasifique imágenes de ropa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysAmHLZoDld7"
      },
      "source": [
        "# Import keras\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHlHs9Wj_PUM"
      },
      "source": [
        "# Download the dataset and split into train and test sets\n",
        "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHkQOzHLoKNA"
      },
      "source": [
        "Para el preprocesamiento, normalizará los valores de los píxeles para que el entrenamiento converja más rápidamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLVhXs3xrUD0"
      },
      "source": [
        "# Normalize pixel values between 0 and 1\n",
        "img_train = img_train.astype('float32') / 255.0\n",
        "img_test = img_test.astype('float32') / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hM19_JWD6eF"
      },
      "source": [
        "## Rendimiento de referencia\n",
        "\n",
        "Como se ha mencionado, primero tendrá un rendimiento de referencia utilizando parámetros elegidos arbitrariamente para poder comparar los resultados más adelante. En interés de los límites de tiempo y recursos proporcionados por Colab, sólo construirá una red neuronal densa superficial (DNN) como se muestra a continuación. Esto es para demostrar los conceptos sin involucrar enormes conjuntos de datos y largos tiempos de sintonización y entrenamiento. Como verás más adelante, incluso los modelos pequeños pueden tardar en afinarse. Puedes ampliar los conceptos aquí cuando llegues a construir modelos más complejos en tus propios proyectos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqbYwwukkA6z"
      },
      "source": [
        "# Construir el modelo de referencia utilizando la API secuencial\n",
        "b_model = keras.Sequential()\n",
        "b_model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "b_model.add(keras.layers.Dense(units=512, activation='relu', name='dense_1')) # You will tune this layer later\n",
        "b_model.add(keras.layers.Dropout(0.2))\n",
        "b_model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Print model summary\n",
        "b_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAlb_KxTK50d"
      },
      "source": [
        "Como se muestra, codificamos todos los hiperparámetros al declarar las capas. Estos incluyen el número de unidades ocultas, la activación y el abandono. Verás cómo puedes ajustar automáticamente algunos de ellos un poco más adelante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM354GIBKdf0"
      },
      "source": [
        "A continuación, configuremos la pérdida, las métricas y el optimizador. La tasa de aprendizaje también es un hiperparámetro que se puede ajustar automáticamente, pero por ahora, vamos a establecerla en `0,001`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp58Ety3pLj2"
      },
      "source": [
        "# Setup the training parameters\n",
        "b_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FxeAlZlLpHI"
      },
      "source": [
        "Con todos los ajustes establecidos, puedes empezar a entrenar el modelo. Hemos fijado el número de épocas en 10, pero no dudes en aumentarlo si tienes más tiempo para pasar por el cuaderno. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1JjZ-FdLXZ3"
      },
      "source": [
        "# Number of training epochs.\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Train the model\n",
        "b_model.fit(img_train, label_train, epochs=NUM_EPOCHS, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6LALxGwMtkV"
      },
      "source": [
        "Por último, se quiere ver cómo se comporta este modelo de referencia frente al conjunto de pruebas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBnZ2tFbpxgC"
      },
      "source": [
        "# Evaluate model on the test set\n",
        "b_eval_dict = b_model.evaluate(img_test, label_test, return_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YCfzg0IM9b6"
      },
      "source": [
        "Vamos a definir una función de ayuda para mostrar los resultados, de modo que sea más fácil compararlos después."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt2dWs0NxnUn"
      },
      "source": [
        "# Definir la función de ayuda\n",
        "def print_results(model, model_name, layer_name, eval_dict):\n",
        "  '''\n",
        "  Imprime los valores de los subparámetros a ajustar, y los resultados de la evaluación del modelo\n",
        "\n",
        "  Args:\n",
        "    model (Modelo) - Modelo Keras a evaluar\n",
        "    model_name (string) - cadena arbitraria para identificar el modelo\n",
        "    layer_name (string) - nombre de la capa a ajustar\n",
        "    eval_dict (dict) - resultados de model.evaluate\n",
        "  '''\n",
        "  print(f'\\n{model_name}:')\n",
        "\n",
        "  print(f'número de unidades en la primera capa densa: {model.get_layer(layer_name).units}')\n",
        "  print(f'tasa de aprendizaje para el optimizador: {model.optimizer.lr.numpy()}')\n",
        "\n",
        "  for key,value in eval_dict.items():\n",
        "    print(f'{key}: {value}')\n",
        "\n",
        "# Print results for baseline model\n",
        "print_results(b_model, 'BASELINE MODEL', 'dense_1', b_eval_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH-RLK3Wxt_X"
      },
      "source": [
        "Eso es todo para obtener los resultados de un único conjunto de hiperparámetros. Como puede ver, este proceso puede ser tedioso si quiere probar diferentes conjuntos de parámetros. Por ejemplo, ¿mejorará su modelo si utiliza `tasa de aprendizaje=0.00001` y `unidades=128`? ¿Y si se combina `0,001` con `256`? El proceso será aún más difícil si decides también afinar el dropout y probar también otras funciones de activación. Keras Tuner resuelve este problema al tener una API para buscar automáticamente el conjunto óptimo. Sólo tendrás que configurarlo una vez y esperar los resultados. Verás cómo se hace esto en las siguientes secciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oyczDXqtWjI"
      },
      "source": [
        "## Keras Tuner\n",
        "\n",
        "Para realizar el hypertuning con Keras Tuner, necesitarás:\n",
        "\n",
        "* Definir el modelo\n",
        "* Seleccionar los hiperparámetros a ajustar\n",
        "* Definir su espacio de búsqueda\n",
        "* Definir la estrategia de búsqueda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "### Instalar e importar paquetes\n",
        "\n",
        "Comenzará instalando e importando los paquetes necesarios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpMLpbt9jcO6"
      },
      "source": [
        "# Install Keras Tuner\n",
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_leAIdFKAxAD"
      },
      "source": [
        "# Import required packages\n",
        "import tensorflow as tf\n",
        "import kerastuner as kt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5YEL2H2Ax3e"
      },
      "source": [
        "### Definir el modelo\n",
        "\n",
        "El modelo que se configura para el hipertuning se denomina *hipermodelo*. Cuando construye este modelo, define el espacio de búsqueda de hiperparámetros además de la arquitectura del modelo. \n",
        "\n",
        "Puede definir un hipermodelo a través de dos enfoques:\n",
        "\n",
        "* Utilizando una función de construcción de modelos\n",
        "* Mediante la [subclase de la clase `HyperModel`](https://keras-team.github.io/keras-tuner/#you-can-use-a-hypermodel-subclass-instead-of-a-model-building-function) de la API Keras Tuner\n",
        "\n",
        "\n",
        "En este laboratorio, adoptará el primer enfoque: utilizará una función de construcción de modelos para definir el modelo de clasificación de imágenes. Esta función devuelve un modelo compilado y utiliza los hiperparámetros que usted define en línea para hipoajustar el modelo. \n",
        "\n",
        "La función que se muestra a continuación básicamente construye el mismo modelo que utilizó anteriormente. La diferencia es que hay dos hiperparámetros que se configuran para el ajuste:\n",
        "\n",
        "* el número de unidades ocultas de la primera capa densa\n",
        "* la tasa de aprendizaje del optimizador Adam\n",
        "\n",
        "Verás que esto se hace con un objeto HyperParameters que configura el hiperparámetro que quieres afinar. Para este ejercicio, lo harás: \n",
        "\n",
        "* utilizar su método `Int()` para definir el espacio de búsqueda de las unidades Densas. Esto le permite establecer un valor mínimo y máximo, así como el tamaño del paso cuando se incrementa entre estos valores. \n",
        "\n",
        "* Utiliza su método `Choice()` para la tasa de aprendizaje. Esto le permite definir valores discretos para incluir en el espacio de búsqueda cuando se hipertunea.\n",
        "\n",
        "Puede ver todos los métodos disponibles y su uso de ejemplo en la [documentación oficial](https://keras-team.github.io/keras-tuner/documentation/hyperparameters/#hyperparameters)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQKodC-jtsva"
      },
      "source": [
        "def model_builder(hp):\n",
        "  '''\n",
        "  Construye el modelo y establece los hiperparámetros a afinar.\n",
        "\n",
        "  Args:\n",
        "    hp - Objeto Keras tuner\n",
        "\n",
        "  Devuelve:\n",
        "    El modelo con los hiperparámetros a afinar\n",
        "  '''\n",
        "  \n",
        "  # Inicializar la API secuencial y empezar a apilar las capas\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Ajuste el número de unidades en la primera capa densa\n",
        "  # Elija un valor óptimo entre 32-512\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu', name='tuned_dense_1'))\n",
        "\n",
        "  # Añadir las siguientes capas\n",
        "  model.add(keras.layers.Dropout(0.2))\n",
        "  model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  # Ajuste la tasa de aprendizaje para el optimizador\n",
        "  # Elija un valor óptimo entre 0,01, 0,001 o 0,0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J1VYw4q3x0b"
      },
      "source": [
        "## Instanciar el sintonizador y realizar el hipertuning\n",
        "\n",
        "Ahora que tienes el constructor del modelo, puedes definir cómo el sintonizador puede encontrar el conjunto óptimo de hiperparámetros, también llamado estrategia de búsqueda. Keras Tuner has [four tuners](https://keras-team.github.io/keras-tuner/documentation/tuners/) disponible con estrategias incorporadas - `RandomSearch`, `Hyperband`, `BayesianOptimization`, y `Sklearn`. \n",
        "\n",
        "En este tutorial, se utilizará el sintonizador Hyperband. El Hyperband es un algoritmo desarrollado específicamente para la optimización de hiperparámetros. Utiliza la asignación adaptativa de recursos y la parada temprana para converger rápidamente en un modelo de alto rendimiento. Para ello, se utiliza un campeonato deportivo en el que el algoritmo entrena a un gran número de modelos durante unas pocas épocas y lleva a la siguiente ronda sólo a la mitad de los modelos con mejores resultados. \n",
        "\n",
        "Puede leer sobre la intuición detrás del algoritmo en la sección 3 de [this paper](https://arxiv.org/pdf/1603.06560.pdf).\n",
        "\n",
        "Hyperband determina el número de modelos a entrenar en un paréntesis calculando 1 + log<sub>`factor`</sub>(`max_epochs`) y redondeándolo al entero más cercano. You will see these parameters (i.e. `factor` and `max_epochs` passed into the initializer below). Además, también necesitarás definir lo siguiente para instanciar el sintonizador Hyperband:\n",
        "\n",
        "* el hipermodelo (construido por su función de construcción de modelos)\n",
        "* el \"objetivo\" a optimizar (por ejemplo, la precisión de la validación)\n",
        "* un \"directorio\" para guardar los registros y puntos de control de cada prueba (configuración del modelo) ejecutada durante la búsqueda de hiperparámetros. Si se vuelve a ejecutar la búsqueda de hiperparámetros, el Afinador Keras utiliza el estado existente de estos registros para reanudar la búsqueda. Para desactivar este comportamiento, pase un argumento adicional `overwrite=True` al instanciar el sintonizador.\n",
        "* el `nombre_del_proyecto` para diferenciarlo de otras ejecuciones. Se utilizará como nombre de subdirectorio bajo el `directorio`.\n",
        "\n",
        "Puedes consultar la [documentación](https://keras.io/api/keras_tuner/tuners/hyperband/) para conocer otros argumentos que puedes pasar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oichQFly6Y46"
      },
      "source": [
        "# Instantiate the tuner\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='kt_dir',\n",
        "                     project_name='kt_hyperband')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij3hGcp4e8QG"
      },
      "source": [
        "Veamos un resumen de los hiperparámetros que se van a sintonizar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmkJOPp5WkiG"
      },
      "source": [
        "# Display hypertuning settings\n",
        "tuner.search_space_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwhBdXx0Ekj8"
      },
      "source": [
        "Puedes pasar una llamada de retorno para detener el entrenamiento antes de tiempo cuando una métrica no está mejorando. A continuación, definimos una devolución de llamada [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) para supervisar la pérdida de validación y detener el entrenamiento si no mejora después de 5 épocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT9IkS9NEjLc"
      },
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKghEo15Tduy"
      },
      "source": [
        "Ahora se ejecutará la búsqueda de hiperparámetros. Los argumentos para el método de búsqueda son los mismos que los utilizados para `tf.keras.model.fit` además del callback anterior. Esto tomará alrededor de 10 minutos para ejecutar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSBQcTHF9cKt"
      },
      "source": [
        "# Perform hypertuning\n",
        "tuner.search(img_train, label_train, epochs=NUM_EPOCHS, validation_split=0.2, callbacks=[stop_early])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewN6WBDYWvRw"
      },
      "source": [
        "Puede obtener el modelo de mayor rendimiento con el método [get_best_hyperparameters()](https://keras-team.github.io/keras-tuner/documentation/tuners/#get_best_hyperparameters-method)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG0zIuP5WuTI"
      },
      "source": [
        "# Obtener los hiperparámetros óptimos a partir de los resultados\n",
        "best_hps=tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "La búsqueda de hiperparámetros está completa. El número óptimo de unidades en la primera capa densamente conectada\n",
        "es {best_hps.get('units')} y la tasa de aprendizaje óptima para el optimizador\n",
        "es {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lak_ylf88xBv"
      },
      "source": [
        "## Construir y entrenar el modelo\n",
        "\n",
        "Ahora que tiene el mejor conjunto de hiperparámetros, puede reconstruir el hipermodelo con estos valores y volver a entrenarlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McO82AXOuxXh"
      },
      "source": [
        "# Build the model with the optimal hyperparameters\n",
        "h_model = tuner.hypermodel.build(best_hps)\n",
        "h_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l64WP7Rau1lm"
      },
      "source": [
        "# Train the hypertuned model\n",
        "h_model.fit(img_train, label_train, epochs=NUM_EPOCHS, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqU5ZVAaag2v"
      },
      "source": [
        "A continuación, obtendrá su rendimiento frente al conjunto de pruebas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E0BTp9Ealjb"
      },
      "source": [
        "# Evaluate the hypertuned model against the test set\n",
        "h_eval_dict = h_model.evaluate(img_test, label_test, return_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQRpPHZsz-eC"
      },
      "source": [
        "Podemos comparar los resultados obtenidos con el modelo de referencia que utilizamos al principio del cuaderno. Los resultados pueden variar, pero normalmente se obtiene un modelo que tiene menos unidades en la capa densa, mientras que tiene una pérdida y precisión comparables. Esto indica que redujiste el tamaño del modelo y ahorraste recursos de computación mientras seguías teniendo más o menos la misma precisión."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjVYPOw6MH5d"
      },
      "source": [
        "# Impresión de los resultados del modelo de referencia y del modelo hipertecnificado\n",
        "print_results(b_model, 'BASELINE MODEL', 'dense_1', b_eval_dict)\n",
        "print_results(h_model, 'HYPERTUNED MODEL', 'tuned_dense_1', h_eval_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKn4g_HzP2KS"
      },
      "source": [
        "## Desafíos extra (opcional)\n",
        "\n",
        "Si quieres seguir practicando con Keras Tuner en este cuaderno, puedes hacer un reset de fábrica (`Runtime > Factory reset runtime`) y enfrentarte a cualquiera de los siguientes:\n",
        "\n",
        "- hipertunear la capa de abandono con `hp.Float()` o `hp.Choice()`\n",
        "- Hiperajustar la función de activación de la 1ª capa densa con `hp.Choice()`.\n",
        "- determinar el número óptimo de capas densas que puede añadir para mejorar el modelo. Puedes usar el código [aquí](https://keras.io/guides/keras_tuner/getting_started/#the-search-space-may-contain-conditional-hyperparameters) como referencia.\n",
        "- explorar las clases predefinidas `HyperModel` - [HyperXception e HyperResNet](https://keras-team.github.io/keras-tuner/documentation/hypermodels/#hyperresnet-class) para aplicaciones de visión por ordenador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKwLOzKpFGAj"
      },
      "source": [
        "## Resumen\n",
        "\n",
        "En este tutorial, usted utilizó el Afinador Keras para afinar convenientemente los hiperparámetros. Se ha definido cuáles son los que hay que ajustar, el espacio de búsqueda y la estrategia de búsqueda para llegar al conjunto óptimo de hiperparámetros. Estos conceptos se discutirán de nuevo en las próximas secciones, pero en el contexto de AutoML, un paquete que automatiza todo el proceso de aprendizaje automático. A continuación.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RJJeqqGrDY5Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}