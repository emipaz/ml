{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EixH_3T4RN9u"
      },
      "source": [
        "# Ungraded lab: Shapley Values\n",
        "------------------------\n",
        " \n",
        "Bienvenido, durante este laboratorio no calificado vas a trabajar con SHAP (SHapley Additive exPlanations). Este procedimiento se deriva de la teoría de juegos y tiene como objetivo comprender (o explicar) la salida de cualquier modelo de aprendizaje automático. En concreto lo harás:\n",
        "\n",
        "\n",
        "1. 1. Entrenar una CNN simple en el conjunto de datos mnist de moda.\n",
        "2. 2. Calcular los valores de Shapley para los ejemplos de cada clase.\n",
        "3. 3. Visualizar estos valores y obtener información a partir de ellos.\n",
        "\n",
        "Para saber más sobre los valores de Shapley, visita el repositorio oficial [SHAP repo](https://github.com/slundberg/shap).\n",
        "\n",
        "¡Vamos a empezar!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7j3OLmgUWzB"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Begin by installing the shap library:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Fzf05Amwpx"
      },
      "source": [
        "!pip install shap\n",
        "!pip install tensorflow==2.4.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SnFiuF_V0MY"
      },
      "source": [
        "Now import all necessary dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5BRI5W3mf5q"
      },
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fZHtO_oWh3_"
      },
      "source": [
        "## Train a CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIB4uc1qhgc9"
      },
      "source": [
        "For this lab you will use the [fashion MNIST](https://keras.io/api/datasets/fashion_mnist/) dataset. Load it and pre-process the data before feeding it into the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ap5dqFQmsDC"
      },
      "source": [
        "# Download the dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Reshape and normalize data\n",
        "x_train = x_train.reshape(60000, 28, 28, 1).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape(10000, 28, 28, 1).astype(\"float32\") / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBak9dOqiI2V"
      },
      "source": [
        "Para el modelo CNN se utilizará una arquitectura simple compuesta por un par de capas convolucionales y maxpooling conectadas a una capa totalmente conectada con 256 unidades y la capa de salida con 10 unidades ya que hay 10 categorías.\n",
        "\n",
        "Define el modelo utilizando la [API Funcional] de Keras (https://keras.io/guides/functional_api/):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH7gEwiksWDE"
      },
      "source": [
        "# Define the model architecture using the functional API\n",
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(256, activation='relu')(x)\n",
        "outputs = keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the model with the corresponding inputs and outputs\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"CNN\")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      optimizer=keras.optimizers.Adam(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "  )\n",
        "\n",
        "# Train it!\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwSN-8STj_bh"
      },
      "source": [
        "A juzgar por las métricas de precisión, parece que el modelo está sobreajustado. Sin embargo, alcanza una precisión superior al 90% en el conjunto de pruebas, por lo que su rendimiento es adecuado para los fines de este laboratorio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJv0LghcmX_P"
      },
      "source": [
        "# Explaining the outputs\n",
        "\n",
        "Sabe que el modelo clasifica correctamente alrededor del 90% de las imágenes del conjunto de prueba. Pero, ¿cómo lo hace? ¿Qué píxeles se utilizan para determinar si una imagen pertenece a una clase determinada?\n",
        "\n",
        "Para responder a estas preguntas puede utilizar los valores SHAP.\n",
        "\n",
        "Antes de hacerlo, compruebe cómo es cada una de las categorías:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSqcehYVxSZY"
      },
      "source": [
        "# Name each one of the classes\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# Save an example for each category in a dict\n",
        "images_dict = dict()\n",
        "for i, l in enumerate(y_train):\n",
        "  if len(images_dict)==10:\n",
        "    break\n",
        "  if l not in images_dict.keys():\n",
        "    images_dict[l] = x_train[i].reshape((28, 28))\n",
        "\n",
        "# Function to plot images\n",
        "def plot_categories(images):\n",
        "  fig, axes = plt.subplots(1, 11, figsize=(16, 15))\n",
        "  axes = axes.flatten()\n",
        "  \n",
        "  # Plot an empty canvas\n",
        "  ax = axes[0]\n",
        "  dummy_array = np.array([[[0, 0, 0, 0]]], dtype='uint8')\n",
        "  ax.set_title(\"reference\")\n",
        "  ax.set_axis_off()\n",
        "  ax.imshow(dummy_array, interpolation='nearest')\n",
        "\n",
        "  # Plot an image for every category\n",
        "  for k,v in images.items():\n",
        "    ax = axes[k+1]\n",
        "    ax.imshow(v, cmap=plt.cm.binary)\n",
        "    ax.set_title(f\"{class_names[k]}\")\n",
        "    ax.set_axis_off()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Use the function to plot\n",
        "plot_categories(images_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPt9q5bDhCGz"
      },
      "source": [
        "Ahora ya sabes cómo son los artículos de cada una de las categorías.\n",
        "\n",
        "Quizá se pregunte para qué sirve la imagen vacía de la izquierda. En breve verás por qué es importante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BjJPAnhhcYS"
      },
      "source": [
        "## DeepExplainer\n",
        "\n",
        "Para calcular los valores de shap del modelo que acabas de entrenar utilizarás la clase `DeepExplainer` de la librería `shap`. \n",
        "\n",
        "Para instanciar esta clase necesitas pasar un modelo junto con los ejemplos de entrenamiento. Observa que no se pasan todos los ejemplos de entrenamiento, sino sólo una fracción de ellos. \n",
        "\n",
        "Esto se hace porque los cálculos realizados por el objeto `DeepExplainer` son muy intensivos en memoria RAM y podrías quedarte sin ella.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fZZQnMWvjc6"
      },
      "source": [
        "# Take a random sample of 5000 training images\n",
        "background = x_train[np.random.choice(x_train.shape[0], 5000, replace=False)]\n",
        "\n",
        "# Use DeepExplainer to explain predictions of the model\n",
        "e = shap.DeepExplainer(model, background)\n",
        "\n",
        "# Compute shap values\n",
        "# shap_values = e.shap_values(x_test[1:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYPuBiOwjEDh"
      },
      "source": [
        "Ahora puede utilizar la instancia `DeepExplainer` para calcular los valores Shap de las imágenes del conjunto de prueba.\n",
        "\n",
        "Para poder visualizar correctamente estos valores para cada clase, cree una matriz que contenga un elemento de cada clase del conjunto de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5InnVMMzvCwl"
      },
      "source": [
        "# Save an example of each class from the test set\n",
        "x_test_dict = dict()\n",
        "for i, l in enumerate(y_test):\n",
        "  if len(x_test_dict)==10:\n",
        "    break\n",
        "  if l not in x_test_dict.keys():\n",
        "    x_test_dict[l] = x_test[i]\n",
        "\n",
        "# Convert to list preserving order of classes\n",
        "x_test_each_class = [x_test_dict[i] for i in sorted(x_test_dict)]\n",
        "\n",
        "# Convert to tensor\n",
        "x_test_each_class = np.asarray(x_test_each_class)\n",
        "\n",
        "# Print shape of tensor\n",
        "print(f\"x_test_each_class tensor has shape: {x_test_each_class.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYNRZ3WkqLfE"
      },
      "source": [
        "Antes de calcular los valores shap, asegúrate de que el modelo es capaz de clasificar correctamente cada uno de los ejemplos que acabas de elegir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gbdJQKcqN6y"
      },
      "source": [
        "# Compute predictions\n",
        "predictions = model.predict(x_test_each_class)\n",
        "\n",
        "# Apply argmax to get predicted class\n",
        "np.argmax(predictions, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNShTEtEqwsQ"
      },
      "source": [
        "Como los ejemplos de prueba están ordenados según el número de clase y la matriz de predicciones también está ordenada, el modelo pudo clasificar correctamente cada una de estas imágenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPXkTm_Ll4Ua"
      },
      "source": [
        "## Visualizing Shap Values\n",
        "\n",
        "Ahora que tienes un ejemplo de cada clase, calcula los valores de Shap para cada ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cm_HjmFuQzF"
      },
      "source": [
        "# Compute shap values using DeepExplainer instance\n",
        "shap_values = e.shap_values(x_test_each_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nogfmvwsmtbl"
      },
      "source": [
        "Ahora echa un vistazo a los valores de shap calculados. Para entender la siguiente ilustración, tenga en cuenta estos puntos:\n",
        "- Los valores shap positivos se denotan en color rojo y representan los píxeles que contribuyeron a clasificar esa imagen como esa clase en particular.\n",
        "- Los valores shap negativos son de color azul y representan los píxeles que han contribuido a NO clasificar la imagen en esa clase.\n",
        "- Cada fila contiene cada una de las imágenes de prueba para las que calculó los valores shap.\n",
        "- Cada columna representa las categorías ordenadas que el modelo podría elegir. Observa que `shap.image_plot` sólo hace una copia de la imagen clasificada, pero puedes usar la función `plot_categories` que creaste antes para mostrar un ejemplo de esa clase como referencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t1dWh7rv0ya"
      },
      "source": [
        "# Plot reference column\n",
        "plot_categories(images_dict)\n",
        "\n",
        "# Print an empty line to separate the two plots\n",
        "print()\n",
        "\n",
        "# Plot shap values\n",
        "shap.image_plot(shap_values, -x_test_each_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqblFhpN1ogy"
      },
      "source": [
        "Ahora tómese su tiempo para comprender lo que le muestra el gráfico. Dado que el modelo es capaz de clasificar correctamente cada una de estas 10 imágenes, tiene sentido que los valores shapley a lo largo de la diagonal sean los más prevalentes. Especialmente los valores positivos, ya que esa es la clase que el modelo predijo (correctamente).\n",
        "\n",
        "\n",
        "¿Qué más puedes deducir de este gráfico? Intenta centrarte en un ejemplo. Por ejemplo, céntrate en **el abrigo**, que es la quinta clase. Parece que el modelo también tenía \"razones\" para clasificarlo como **chompa** o **camiseta**. Esto puede deducirse de la presencia de valores shap positivos para estas clases.\n",
        "\n",
        "Echemos un vistazo al tensor de predicciones para comprobar si es así:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGorLRbV2qz7"
      },
      "source": [
        "# Save the probability of belonging to each class for the fifth element of the set\n",
        "coat_probs = predictions[4]\n",
        "\n",
        "# Order the probabilities in ascending order\n",
        "coat_args = np.argsort(coat_probs)\n",
        "\n",
        "# Reverse the list and get the top 3 probabilities\n",
        "top_coat_args = coat_args[::-1][:3]\n",
        "\n",
        "# Print (ordered) top 3 classes\n",
        "for i in list(top_coat_args):\n",
        "  print(class_names[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-HDSUT64AdG"
      },
      "source": [
        "De hecho, el modelo seleccionó estas 3 clases como las más probables para la imagen del **abrigo**. Esto tiene sentido ya que estos objetos son similares entre sí.\n",
        "\n",
        "\n",
        "Observemos ahora la **camiseta**, que es la primera clase. Este objeto es muy similar al jersey, pero sin las mangas largas. No es de extrañar que los píxeles blancos de la zona en la que están las mangas largas arrojen valores shap altos para clasificar como **camiseta**. Del mismo modo, los píxeles blancos de esta zona arrojarán valores shap negativos para la clasificación como **pullover**, ya que el modelo esperará que estos píxeles sean de color si la prenda fuera realmente un **pullover**.\n",
        "\n",
        "\n",
        "Puede obtener mucha información repitiendo este proceso para todas las clases. ¿A qué otras conclusiones puede llegar?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k1-8uGotB4E"
      },
      "source": [
        "-----------------------------\n",
        "**Ahora deberías tener una comprensión más clara de lo que son los valores de Shapley, por qué son útiles y cómo calcularlos utilizando la biblioteca `shap`. \n",
        "\n",
        "Los modelos de aprendizaje profundo se han considerado cajas negras durante mucho tiempo. Existe un equilibrio natural entre la capacidad de predicción y la explanaibilidad en el Aprendizaje Automático, pero gracias al auge de nuevas técnicas como las exPlanificaciones Aditivas de SHapley es más fácil que nunca explicar los resultados de los modelos de Aprendizaje Profundo.\n",
        "\n",
        "\n",
        "**Sigue así**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JClpYo6THwTQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}